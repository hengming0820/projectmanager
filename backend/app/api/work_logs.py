from fastapi import APIRouter, Depends, HTTPException, status, Body
from fastapi.responses import StreamingResponse
from sqlalchemy.orm import Session, joinedload
from sqlalchemy import and_, or_, func, desc
from typing import List, Optional
from datetime import datetime, date, timedelta
from app.utils.datetime_utils import utc_now
import uuid
import logging

from app.database import get_db
from app.models.work_log import WorkWeek, WorkLogEntry, WorkLogType
from app.models.user import User
from app.schemas.work_log import (
    WorkWeekCreate, WorkWeekUpdate, WorkWeekResponse, WorkWeekQueryParams,
    WorkLogEntryCreate, WorkLogEntryUpdate, WorkLogEntrySubmit, WorkLogEntryReview,
    WorkLogEntryResponse, WorkLogQueryParams,
    WorkLogTypeCreate, WorkLogTypeUpdate, WorkLogTypeResponse,
    WorkWeekSummary, WorkWeekStatistics, WorkLogBatchCreate
)
from app.utils.security import get_current_user
from app.utils.permissions import require_permission
from app.services.pdf_export_service import work_log_pdf_service

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/work-logs", tags=["work-logs"])

# ==================== å·¥ä½œå‘¨ç®¡ç† ====================

@router.post("/weeks")
async def create_work_week(
    work_week: WorkWeekCreate,
    auto_init: bool = False,
    db: Session = Depends(get_db),
    current_user: User = Depends(require_permission("WorkLogManagement"))
):
    """åˆ›å»ºå·¥ä½œå‘¨ï¼ˆç®¡ç†å‘˜æƒé™ï¼‰"""
    try:
        print(f"ğŸ”¨ [WorkLogAPI] åˆ›å»ºå·¥ä½œå‘¨ï¼Œç”¨æˆ·: {current_user.username}, æ•°æ®: {work_week}")
        
        # éªŒè¯æ—¥æœŸèŒƒå›´ï¼ˆç¡®ä¿æ˜¯ä¸€ä¸ªå®Œæ•´çš„å·¥ä½œå‘¨ï¼‰
        if (work_week.week_end_date - work_week.week_start_date).days != 4:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="å·¥ä½œå‘¨å¿…é¡»æ˜¯5å¤©ï¼ˆå‘¨ä¸€åˆ°å‘¨äº”ï¼‰"
            )
        
        # æ”¾å®½é™åˆ¶ï¼šå…è®¸åŒæ—¶é—´æ®µåˆ›å»ºå¤šä¸ªå·¥ä½œå‘¨ï¼ˆç”¨äºè¦†ç›–ä¸åŒå‘˜å·¥é›†ï¼‰
        # ä»…å½“å®Œå…¨ç›¸åŒæ—¶é—´æ®µä¸”æ ‡é¢˜ä¹Ÿç›¸åŒï¼Œæ‰è‡ªåŠ¨è°ƒæ•´æ ‡é¢˜é¿å…å†²çª
        same_range_weeks = db.query(WorkWeek).filter(
            WorkWeek.week_start_date == work_week.week_start_date,
            WorkWeek.week_end_date == work_week.week_end_date,
            WorkWeek.status == "active"
        ).all()
        if same_range_weeks:
            base_title = work_week.title or "å·¥ä½œå‘¨"
            # è‹¥å·²æœ‰åŒåï¼Œåˆ™è¿½åŠ åºå·åç¼€
            conflict_count = sum(1 for w in same_range_weeks if (w.title or "") == base_title)
            if conflict_count > 0:
                work_week_dict = work_week.dict()
                work_week_dict["title"] = f"{base_title}({conflict_count + 1})"
                work_week = WorkWeekCreate(**work_week_dict)
        
        # åˆ›å»ºå·¥ä½œå‘¨
        db_work_week = WorkWeek(
            id=str(uuid.uuid4()),
            **work_week.dict(),
            created_by=current_user.id
        )
        
        db.add(db_work_week)
        db.commit()
        db.refresh(db_work_week)
        
        print(f"âœ… [WorkLogAPI] å·¥ä½œå‘¨åˆ›å»ºæˆåŠŸ: {db_work_week.id}, æ ‡é¢˜: {db_work_week.title}")
        
        # å¯é€‰ï¼šä¸ºæŒ‡å®šç”¨æˆ·ç”Ÿæˆç©ºç™½æ¡ç›®ï¼ˆè‹¥ config.covered_user_ids æä¾›åˆ™åªç”Ÿæˆè¿™äº›äººï¼‰
        if auto_init:
            covered_user_ids = None
            try:
                if db_work_week.config and isinstance(db_work_week.config, dict):
                    covered_user_ids = db_work_week.config.get('covered_user_ids')
                    if covered_user_ids and not isinstance(covered_user_ids, list):
                        covered_user_ids = None
            except Exception:
                covered_user_ids = None
            if covered_user_ids:
                # æŒ‰é€‰æ‹©çš„ç”¨æˆ·ç”Ÿæˆ
                await _generate_entries_for_specific_users(db, db_work_week, covered_user_ids)
            else:
                await _create_default_entries_for_week(db, db_work_week)
            print(f"âœ… [WorkLogAPI] å·¥ä½œå‘¨åˆ›å»ºå®Œæˆï¼Œå·²ä¸ºæ´»è·ƒç”¨æˆ·åˆå§‹åŒ–æ¡ç›®")
        else:
            print(f"âœ… [WorkLogAPI] å·¥ä½œå‘¨åˆ›å»ºå®Œæˆï¼ˆæœªåˆå§‹åŒ–æ¡ç›®ï¼‰")
        
        # æ„å»ºæ ‡å‡†å“åº”æ ¼å¼
        return {
            "code": 200,
            "msg": "success",
            "data": {
                "id": db_work_week.id,
                "title": db_work_week.title,
                "week_start_date": db_work_week.week_start_date.isoformat(),
                "week_end_date": db_work_week.week_end_date.isoformat(),
                "description": db_work_week.description,
                "status": db_work_week.status,
                "config": db_work_week.config,
                "created_by": db_work_week.created_by,
                "created_at": db_work_week.created_at.isoformat(),
                "updated_at": db_work_week.updated_at.isoformat()
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ [WorkLogAPI] åˆ›å»ºå·¥ä½œå‘¨å¤±è´¥: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ›å»ºå·¥ä½œå‘¨å¤±è´¥: {str(e)}"
        )

@router.get("/weeks")
async def get_work_weeks(
    params: WorkWeekQueryParams = Depends(),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """è·å–å·¥ä½œå‘¨åˆ—è¡¨"""
    try:
        print(f"ğŸ“‹ [WorkLogAPI] è·å–å·¥ä½œå‘¨åˆ—è¡¨ï¼Œç”¨æˆ·: {current_user.username}")
        
        query = db.query(WorkWeek)
        
        # è¿‡æ»¤æ¡ä»¶
        if params.status:
            query = query.filter(WorkWeek.status == params.status)
        if params.date_start:
            query = query.filter(WorkWeek.week_start_date >= params.date_start)
        if params.date_end:
            query = query.filter(WorkWeek.week_end_date <= params.date_end)
        if params.created_by:
            query = query.filter(WorkWeek.created_by == params.created_by)
        
        # åˆ†é¡µ
        total = query.count()
        print(f"ğŸ“Š [WorkLogAPI] æ‰¾åˆ° {total} ä¸ªå·¥ä½œå‘¨")
        
        work_weeks = query.order_by(desc(WorkWeek.week_start_date)).offset(
            (params.page - 1) * params.page_size
        ).limit(params.page_size).all()
        
        print(f"ğŸ“„ [WorkLogAPI] å½“å‰é¡µ {len(work_weeks)} ä¸ªå·¥ä½œå‘¨")
        
        # æ„å»ºå“åº”æ•°æ®ï¼Œæ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        week_responses = []
        for week in work_weeks:
            entries = db.query(WorkLogEntry).filter(WorkLogEntry.work_week_id == week.id).all()
            total_entries = len(entries)
            submitted_entries = len([e for e in entries if e.status in ["submitted", "approved"]])
            completion_rate = (submitted_entries / total_entries * 100) if total_entries > 0 else 0
            
            # æ„å»ºå“åº”å¯¹è±¡
            week_data = {
                "id": week.id,
                "title": week.title,
                "week_start_date": week.week_start_date.isoformat(),
                "week_end_date": week.week_end_date.isoformat(),
                "description": week.description,
                "status": week.status,
                "config": week.config,
                "created_by": week.created_by,
                "created_at": week.created_at.isoformat(),
                "updated_at": week.updated_at.isoformat(),
                "total_entries": total_entries,
                "submitted_entries": submitted_entries,
                "completion_rate": completion_rate
            }
            week_responses.append(week_data)
        
        result = {
            "code": 200,
            "msg": "success",
            "data": {
                "list": week_responses,
                "total": total
            }
        }
        
        print(f"âœ… [WorkLogAPI] è¿”å›å“åº”: {len(week_responses)} ä¸ªå·¥ä½œå‘¨, æ€»è®¡: {total}")
        return result
        
    except Exception as e:
        print(f"âŒ [WorkLogAPI] è·å–å·¥ä½œå‘¨åˆ—è¡¨å¤±è´¥: {e}")
        raise

@router.get("/weeks/{week_id}")
async def get_work_week(
    week_id: str,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """è·å–å·¥ä½œå‘¨è¯¦æƒ…"""
    try:
        work_week = db.query(WorkWeek).filter(WorkWeek.id == week_id).first()
        if not work_week:
            print(f"âŒ [WorkLogAPI] å·¥ä½œå‘¨ä¸å­˜åœ¨: {week_id}")
            raise HTTPException(status_code=404, detail="å·¥ä½œå‘¨ä¸å­˜åœ¨")
        
        print(f"âœ… [WorkLogAPI] æ‰¾åˆ°å·¥ä½œå‘¨: {work_week.title}")
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        entries = db.query(WorkLogEntry).filter(WorkLogEntry.work_week_id == week_id).all()
        total_entries = len(entries)
        submitted_entries = len([e for e in entries if e.status in ["submitted", "approved"]])
        completion_rate = (submitted_entries / total_entries * 100) if total_entries > 0 else 0
        
        # æ„å»ºæ ‡å‡†å“åº”
        result = {
            "code": 200,
            "msg": "success",
            "data": {
                "id": work_week.id,
                "title": work_week.title,
                "week_start_date": work_week.week_start_date.isoformat(),
                "week_end_date": work_week.week_end_date.isoformat(),
                "description": work_week.description,
                "status": work_week.status,
                "config": work_week.config,
                "created_by": work_week.created_by,
                "created_at": work_week.created_at.isoformat(),
                "updated_at": work_week.updated_at.isoformat(),
                "total_entries": total_entries,
                "submitted_entries": submitted_entries,
                "completion_rate": completion_rate
            }
        }
        
        print(f"âœ… [WorkLogAPI] è¿”å›å·¥ä½œå‘¨è¯¦æƒ…: {work_week.title}")
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ [WorkLogAPI] è·å–å·¥ä½œå‘¨è¯¦æƒ…å¤±è´¥: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–å·¥ä½œå‘¨è¯¦æƒ…å¤±è´¥: {str(e)}"
        )

@router.put("/weeks/{week_id}", response_model=WorkWeekResponse)
async def update_work_week(
    week_id: str,
    work_week_update: WorkWeekUpdate,
    db: Session = Depends(get_db),
    current_user: User = Depends(require_permission("WorkLogManagement"))
):
    """æ›´æ–°å·¥ä½œå‘¨"""
    
    work_week = db.query(WorkWeek).filter(WorkWeek.id == week_id).first()
    if not work_week:
        raise HTTPException(status_code=404, detail="å·¥ä½œå‘¨ä¸å­˜åœ¨")
    
    # æ›´æ–°å­—æ®µ
    for field, value in work_week_update.dict(exclude_unset=True).items():
        setattr(work_week, field, value)
    
    work_week.updated_at = utc_now()
    db.commit()
    db.refresh(work_week)
    
    return work_week

@router.delete("/weeks/{week_id}")
async def delete_work_week(
    week_id: str,
    db: Session = Depends(get_db),
    current_user: User = Depends(require_permission("WorkLogManagement"))
):
    """åˆ é™¤å·¥ä½œå‘¨ï¼ˆç¡¬åˆ é™¤ï¼ŒåŒæ—¶åˆ é™¤ç›¸å…³å·¥ä½œé¡¹ï¼‰"""
    
    work_week = db.query(WorkWeek).filter(WorkWeek.id == week_id).first()
    if not work_week:
        raise HTTPException(status_code=404, detail="å·¥ä½œå‘¨ä¸å­˜åœ¨")
    
    print(f"ğŸ—‘ï¸ [WorkLogAPI] å¼€å§‹åˆ é™¤å·¥ä½œå‘¨: {work_week.id}, æ ‡é¢˜: {work_week.title}")
    
    # é¦–å…ˆåˆ é™¤è¯¥å·¥ä½œå‘¨ä¸‹çš„æ‰€æœ‰å·¥ä½œæ—¥å¿—æ¡ç›®
    work_entries = db.query(WorkLogEntry).filter(WorkLogEntry.work_week_id == week_id).all()
    entries_count = len(work_entries)
    
    if entries_count > 0:
        print(f"ğŸ“‹ [WorkLogAPI] å‘ç° {entries_count} ä¸ªç›¸å…³å·¥ä½œé¡¹ï¼Œå¼€å§‹åˆ é™¤...")
        for entry in work_entries:
            db.delete(entry)
        print(f"âœ… [WorkLogAPI] å·²åˆ é™¤ {entries_count} ä¸ªå·¥ä½œé¡¹")
    else:
        print(f"ğŸ“‹ [WorkLogAPI] è¯¥å·¥ä½œå‘¨ä¸‹æ²¡æœ‰å·¥ä½œé¡¹")
    
    # ç„¶ååˆ é™¤å·¥ä½œå‘¨æœ¬èº«
    db.delete(work_week)
    db.commit()
    
    print(f"âœ… [WorkLogAPI] å·¥ä½œå‘¨åˆ é™¤å®Œæˆ: {work_week.title}")
    
    return {
        "code": 200,
        "msg": "success",
        "data": {
            "message": "å·¥ä½œå‘¨åŠç›¸å…³å·¥ä½œé¡¹å·²å½»åº•åˆ é™¤",
            "deleted_entries_count": entries_count
        }
    }

# ==================== å·¥ä½œæ—¥å¿—æ¡ç›®ç®¡ç† ====================

@router.get("/weeks/{week_id}/entries")
async def get_work_log_entries(
    week_id: str,
    user_id: Optional[str] = None,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """è·å–å·¥ä½œå‘¨çš„æ—¥å¿—æ¡ç›®"""
    try:
        print("ğŸ”¥ğŸ”¥ğŸ”¥ [WorkLogAPI] æ–°ç‰ˆæœ¬APIè¢«è°ƒç”¨ï¼ğŸ”¥ğŸ”¥ğŸ”¥")
        print(f"ğŸ“‹ [WorkLogAPI] è·å–å·¥ä½œå‘¨æ—¥å¿—æ¡ç›®ï¼Œå·¥ä½œå‘¨ID: {week_id}, ç”¨æˆ·: {current_user.username}")
        if user_id:
            print(f"ğŸ“‹ [WorkLogAPI] ç­›é€‰ç”¨æˆ·ID: {user_id}")
        
        # éªŒè¯å·¥ä½œå‘¨å­˜åœ¨
        work_week = db.query(WorkWeek).filter(WorkWeek.id == week_id).first()
        if not work_week:
            print(f"âŒ [WorkLogAPI] å·¥ä½œå‘¨ä¸å­˜åœ¨: {week_id}")
            raise HTTPException(status_code=404, detail="å·¥ä½œå‘¨ä¸å­˜åœ¨")
        
        print(f"âœ… [WorkLogAPI] æ‰¾åˆ°å·¥ä½œå‘¨: {work_week.title}")
        
        query = db.query(WorkLogEntry).options(
            joinedload(WorkLogEntry.user),
            joinedload(WorkLogEntry.reviewer)
        ).filter(WorkLogEntry.work_week_id == week_id)
        
        # å¦‚æœæŒ‡å®šäº†ç”¨æˆ·IDï¼Œåªè¿”å›è¯¥ç”¨æˆ·çš„æ¡ç›®
        if user_id:
            query = query.filter(WorkLogEntry.user_id == user_id)
        
        entries = query.order_by(WorkLogEntry.work_date, WorkLogEntry.user_id).all()
        print(f"ğŸ“Š [WorkLogAPI] æ‰¾åˆ° {len(entries)} ä¸ªå·¥ä½œæ—¥å¿—æ¡ç›®")
        
        # æ„å»ºæ ‡å‡†å“åº”æ•°æ®
        entries_data = []
        for entry in entries:
            entry_data = {
                "id": entry.id,
                "work_week_id": entry.work_week_id,
                "user_id": entry.user_id,
                "work_date": entry.work_date.isoformat(),
                "day_of_week": entry.day_of_week,
                "work_type": entry.work_type,
                "planned_hours": entry.planned_hours,
                "actual_hours": entry.actual_hours,
                "completion_rate": entry.completion_rate,
                "status": entry.status,
                "priority": entry.priority,
                "work_content": entry.work_content,
                "difficulties": entry.difficulties,
                "next_day_plan": entry.next_day_plan,
                "remarks": entry.remarks,
                "submitted_at": entry.submitted_at.isoformat() if entry.submitted_at else None,
                "reviewed_at": entry.reviewed_at.isoformat() if entry.reviewed_at else None,
                "reviewed_by": entry.reviewed_by,
                "review_comment": entry.review_comment,
                "created_at": entry.created_at.isoformat(),
                "updated_at": entry.updated_at.isoformat()
            }
            
            # æ·»åŠ å…³è”ä¿¡æ¯
            if entry.user:
                entry_data["user_name"] = getattr(entry.user, 'real_name', None) or getattr(entry.user, 'username', '')
            if entry.reviewer:
                entry_data["reviewer_name"] = getattr(entry.reviewer, 'real_name', None) or getattr(entry.reviewer, 'username', '')
            
            # è·å–å·¥ä½œç±»å‹ä¿¡æ¯
            if entry.work_type:
                work_type = db.query(WorkLogType).filter(WorkLogType.name == entry.work_type).first()
                if work_type:
                    entry_data["work_type_info"] = {
                        "id": work_type.id,
                        "name": work_type.name,
                        "description": work_type.description,
                        "color": work_type.color
                    }
            
            entries_data.append(entry_data)
        
        # æ„å»ºæ ‡å‡†å“åº”
        result = {
            "code": 200,
            "msg": "success",
            "data": entries_data
        }
        
        print(f"âœ… [WorkLogAPI] è¿”å› {len(entries_data)} ä¸ªå·¥ä½œæ—¥å¿—æ¡ç›®")
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ [WorkLogAPI] è·å–å·¥ä½œæ—¥å¿—æ¡ç›®å¤±è´¥: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–å·¥ä½œæ—¥å¿—æ¡ç›®å¤±è´¥: {str(e)}"
        )

@router.post("/entries")
async def create_work_log_entry(
    entry: WorkLogEntryCreate,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """åˆ›å»ºå·¥ä½œæ—¥å¿—æ¡ç›®"""
    
    # éªŒè¯å·¥ä½œå‘¨å­˜åœ¨
    work_week = db.query(WorkWeek).filter(WorkWeek.id == entry.work_week_id).first()
    if not work_week:
        raise HTTPException(status_code=404, detail="å·¥ä½œå‘¨ä¸å­˜åœ¨")
    
    # è®¡ç®—æ˜ŸæœŸå‡ 
    day_of_week = entry.work_date.weekday() + 1  # Python weekday: 0=Monday, è½¬æ¢ä¸º 1=Monday
    
    # ç§»é™¤å”¯ä¸€æ€§é™åˆ¶ - æ”¯æŒæ¯å¤©å¤šä¸ªå·¥ä½œé¡¹
    # æ³¨é‡Šï¼šå…è®¸åŒä¸€ç”¨æˆ·åœ¨åŒä¸€æ—¥æœŸåˆ›å»ºå¤šä¸ªå·¥ä½œæ—¥å¿—æ¡ç›®
    print(f"ğŸ“ [WorkLogAPI] å…è®¸åˆ›å»ºå¤šä¸ªå·¥ä½œé¡¹ï¼Œç”¨æˆ·: {current_user.id}, æ—¥æœŸ: {entry.work_date}")
    
    # åˆ›å»ºæ¡ç›®
    db_entry = WorkLogEntry(
        id=str(uuid.uuid4()),
        **entry.dict(),
        user_id=current_user.id,
        day_of_week=day_of_week
    )
    
    db.add(db_entry)
    db.commit()
    db.refresh(db_entry)
    
    print(f"âœ… [WorkLogAPI] å·¥ä½œæ—¥å¿—æ¡ç›®åˆ›å»ºæˆåŠŸ: {db_entry.id}")
    
    # ç›´æ¥è¿”å›æ•°æ®åº“æ¡ç›®ï¼Œä¸å…¶ä»–APIä¿æŒä¸€è‡´
    return db_entry

@router.put("/entries/{entry_id}", response_model=WorkLogEntryResponse)
async def update_work_log_entry(
    entry_id: str,
    entry_update: WorkLogEntryUpdate,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """æ›´æ–°å·¥ä½œæ—¥å¿—æ¡ç›®"""
    
    entry = db.query(WorkLogEntry).filter(WorkLogEntry.id == entry_id).first()
    if not entry:
        raise HTTPException(status_code=404, detail="å·¥ä½œæ—¥å¿—æ¡ç›®ä¸å­˜åœ¨")
    
    # æƒé™æ£€æŸ¥ï¼šåªèƒ½ä¿®æ”¹è‡ªå·±çš„æ¡ç›®ï¼Œé™¤éæ˜¯ç®¡ç†å‘˜
    if entry.user_id != current_user.id:
        # æ£€æŸ¥æ˜¯å¦æœ‰ç®¡ç†æƒé™
        from app.utils.permissions import check_permission
        if not check_permission(db, current_user, "WorkLogManagement"):
            raise HTTPException(status_code=403, detail="æ²¡æœ‰æƒé™ä¿®æ”¹æ­¤æ¡ç›®")
    
    # æ£€æŸ¥çŠ¶æ€ï¼šå·²æäº¤æˆ–å·²å®¡æ ¸çš„æ¡ç›®ä¸èƒ½ä¿®æ”¹ï¼ˆé™¤éæ˜¯ç®¡ç†å‘˜ï¼‰
    if entry.status in ["submitted", "approved", "rejected"] and entry.user_id == current_user.id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="å·²æäº¤æˆ–å·²å®¡æ ¸çš„æ¡ç›®ä¸èƒ½ä¿®æ”¹"
        )
    
    # æ›´æ–°å­—æ®µ
    for field, value in entry_update.dict(exclude_unset=True).items():
        setattr(entry, field, value)
    
    entry.updated_at = utc_now()
    db.commit()
    db.refresh(entry)
    
    return entry

@router.delete("/entries/{entry_id}")
async def delete_work_log_entry(
    entry_id: str,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """åˆ é™¤å·¥ä½œæ—¥å¿—æ¡ç›®"""
    try:
        print(f"ğŸ—‘ï¸ [WorkLogAPI] åˆ é™¤å·¥ä½œæ—¥å¿—æ¡ç›®: {entry_id}")
        
        entry = db.query(WorkLogEntry).filter(WorkLogEntry.id == entry_id).first()
        if not entry:
            print(f"âŒ [WorkLogAPI] å·¥ä½œæ—¥å¿—æ¡ç›®ä¸å­˜åœ¨: {entry_id}")
            raise HTTPException(status_code=404, detail="å·¥ä½œæ—¥å¿—æ¡ç›®ä¸å­˜åœ¨")
        
        print(f"ğŸ“Š [WorkLogAPI] æ¡ç›®çŠ¶æ€: {entry.status}, ç”¨æˆ·: {entry.user_id}, å½“å‰ç”¨æˆ·: {current_user.id}")
        
        # æƒé™æ£€æŸ¥ï¼šåªæœ‰æ¡ç›®åˆ›å»ºè€…æˆ–ç®¡ç†å‘˜å¯ä»¥åˆ é™¤
        if entry.user_id != current_user.id and current_user.role not in ['admin', 'super']:
            print(f"âŒ [WorkLogAPI] æƒé™ä¸è¶³ï¼Œæ¡ç›®ç”¨æˆ·: {entry.user_id}, å½“å‰ç”¨æˆ·: {current_user.id}, è§’è‰²: {current_user.role}")
            raise HTTPException(status_code=403, detail="åªèƒ½åˆ é™¤è‡ªå·±çš„å·¥ä½œæ—¥å¿—æˆ–éœ€è¦ç®¡ç†å‘˜æƒé™")
        
        # çŠ¶æ€æ£€æŸ¥ï¼šåªæœ‰æœªæäº¤æˆ–å·²é©³å›çš„æ¡ç›®å¯ä»¥åˆ é™¤
        if entry.status not in ["pending", "rejected"]:
            print(f"âŒ [WorkLogAPI] çŠ¶æ€é”™è¯¯ï¼Œå½“å‰çŠ¶æ€: {entry.status}")
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"åªèƒ½åˆ é™¤å¾…å¡«å†™æˆ–å·²é©³å›çš„æ¡ç›®ï¼Œå½“å‰çŠ¶æ€: {entry.status}"
            )
        
        # åˆ é™¤æ¡ç›®
        db.delete(entry)
        db.commit()
        
        print(f"âœ… [WorkLogAPI] åˆ é™¤æˆåŠŸ")
        return {"message": "åˆ é™¤æˆåŠŸ", "id": entry_id}
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ [WorkLogAPI] åˆ é™¤å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"åˆ é™¤å¤±è´¥: {str(e)}")

@router.post("/entries/{entry_id}/submit", response_model=WorkLogEntryResponse)
async def submit_work_log_entry(
    entry_id: str,
    submit_data: WorkLogEntrySubmit,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """æäº¤å·¥ä½œæ—¥å¿—æ¡ç›®"""
    try:
        print(f"ğŸ”¥ğŸ”¥ğŸ”¥ [WorkLogAPI] æäº¤å·¥ä½œæ—¥å¿—æ¡ç›®: {entry_id}")
        print(f"ğŸ“‹ [WorkLogAPI] æäº¤æ•°æ®: {submit_data.dict()}")
        
        entry = db.query(WorkLogEntry).filter(WorkLogEntry.id == entry_id).first()
        if not entry:
            print(f"âŒ [WorkLogAPI] å·¥ä½œæ—¥å¿—æ¡ç›®ä¸å­˜åœ¨: {entry_id}")
            raise HTTPException(status_code=404, detail="å·¥ä½œæ—¥å¿—æ¡ç›®ä¸å­˜åœ¨")
        
        print(f"ğŸ“Š [WorkLogAPI] æ¡ç›®çŠ¶æ€: {entry.status}, ç”¨æˆ·: {entry.user_id}")
        
        # æƒé™æ£€æŸ¥
        if entry.user_id != current_user.id:
            print(f"âŒ [WorkLogAPI] æƒé™é”™è¯¯ï¼Œæ¡ç›®ç”¨æˆ·: {entry.user_id}, å½“å‰ç”¨æˆ·: {current_user.id}")
            raise HTTPException(status_code=403, detail="åªèƒ½æäº¤è‡ªå·±çš„å·¥ä½œæ—¥å¿—")
        
        # çŠ¶æ€æ£€æŸ¥
        if entry.status != "pending":
            print(f"âŒ [WorkLogAPI] çŠ¶æ€é”™è¯¯ï¼Œå½“å‰çŠ¶æ€: {entry.status}, æœŸæœ›: pending")
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"åªèƒ½æäº¤å¾…å¡«å†™çŠ¶æ€çš„æ¡ç›®ï¼Œå½“å‰çŠ¶æ€: {entry.status}"
            )
        
        # æ›´æ–°æ¡ç›®
        print(f"ğŸ“ [WorkLogAPI] æ›´æ–°æ¡ç›®: actual_hours={submit_data.actual_hours}, completion_rate={submit_data.completion_rate}")
        entry.actual_hours = submit_data.actual_hours
        entry.completion_rate = submit_data.completion_rate
        if submit_data.remarks:
            entry.remarks = submit_data.remarks
        entry.status = "submitted"
        entry.submitted_at = utc_now()
        entry.updated_at = utc_now()
        
        db.commit()
        db.refresh(entry)
        
        print(f"âœ… [WorkLogAPI] æäº¤æˆåŠŸï¼Œæ–°çŠ¶æ€: {entry.status}")
        return entry
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ [WorkLogAPI] æäº¤å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"æäº¤å¤±è´¥: {str(e)}")

@router.post("/entries/{entry_id}/review", response_model=WorkLogEntryResponse)
async def review_work_log_entry(
    entry_id: str,
    review_data: WorkLogEntryReview,
    db: Session = Depends(get_db),
    current_user: User = Depends(require_permission("WorkLogReview"))
):
    """å®¡æ ¸å·¥ä½œæ—¥å¿—æ¡ç›®"""
    
    entry = db.query(WorkLogEntry).filter(WorkLogEntry.id == entry_id).first()
    if not entry:
        raise HTTPException(status_code=404, detail="å·¥ä½œæ—¥å¿—æ¡ç›®ä¸å­˜åœ¨")
    
    # çŠ¶æ€æ£€æŸ¥
    if entry.status != "submitted":
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="åªèƒ½å®¡æ ¸å·²æäº¤çš„æ¡ç›®"
        )
    
    # æ›´æ–°å®¡æ ¸ä¿¡æ¯
    entry.status = review_data.status
    entry.review_comment = review_data.review_comment
    entry.reviewed_by = current_user.id
    entry.reviewed_at = utc_now()
    entry.updated_at = utc_now()
    
    db.commit()
    db.refresh(entry)
    
    return entry

# ==================== å·¥ä½œç±»å‹ç®¡ç† ====================

@router.get("/types")
async def get_work_log_types(
    is_active: Optional[bool] = None,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """è·å–å·¥ä½œç±»å‹åˆ—è¡¨"""
    try:
        print("ğŸ”¥ğŸ”¥ğŸ”¥ [WorkLogAPI] è·å–å·¥ä½œç±»å‹åˆ—è¡¨")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥ä½œç±»å‹æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ›å»ºé»˜è®¤ç±»å‹
        type_count = db.query(WorkLogType).count()
        if type_count == 0:
            print("ğŸ“ [WorkLogAPI] åˆ›å»ºé»˜è®¤å·¥ä½œç±»å‹")
            default_types = [
                {"name": "å¼€å‘", "description": "è½¯ä»¶å¼€å‘å·¥ä½œ", "color": "#409EFF", "icon": "code", "sort_order": 1},
                {"name": "æµ‹è¯•", "description": "è½¯ä»¶æµ‹è¯•å·¥ä½œ", "color": "#67C23A", "icon": "test", "sort_order": 2},
                {"name": "ä¼šè®®", "description": "å„ç±»ä¼šè®®", "color": "#E6A23C", "icon": "meeting", "sort_order": 3},
                {"name": "å­¦ä¹ ", "description": "æŠ€æœ¯å­¦ä¹ å’ŒåŸ¹è®­", "color": "#909399", "icon": "study", "sort_order": 4},
                {"name": "å…¶ä»–", "description": "å…¶ä»–å·¥ä½œ", "color": "#F56C6C", "icon": "other", "sort_order": 5}
            ]
            
            for type_data in default_types:
                work_type = WorkLogType(
                    id=str(uuid.uuid4()),
                    **type_data
                )
                db.add(work_type)
            db.commit()
        
        query = db.query(WorkLogType)
        
        if is_active is not None:
            query = query.filter(WorkLogType.is_active == is_active)
        
        types_list = query.order_by(WorkLogType.sort_order, WorkLogType.name).all()
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        types_data = []
        for work_type in types_list:
            types_data.append({
                "id": work_type.id,
                "name": work_type.name,
                "description": work_type.description,
                "color": work_type.color,
                "icon": work_type.icon,
                "is_active": work_type.is_active,
                "sort_order": work_type.sort_order,
                "created_at": work_type.created_at.isoformat(),
                "updated_at": work_type.updated_at.isoformat()
            })
        
        print(f"âœ… [WorkLogAPI] è¿”å› {len(types_data)} ä¸ªå·¥ä½œç±»å‹")
        
        return {
            "code": 200,
            "msg": "success",
            "data": types_data
        }
        
    except Exception as e:
        print(f"âŒ [WorkLogAPI] è·å–å·¥ä½œç±»å‹å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"è·å–å·¥ä½œç±»å‹å¤±è´¥: {str(e)}")

@router.post("/types", response_model=WorkLogTypeResponse)
async def create_work_log_type(
    work_type: WorkLogTypeCreate,
    db: Session = Depends(get_db),
    current_user: User = Depends(require_permission("WorkLogManagement"))
):
    """åˆ›å»ºå·¥ä½œç±»å‹"""
    
    # æ£€æŸ¥åç§°æ˜¯å¦å·²å­˜åœ¨
    existing_type = db.query(WorkLogType).filter(WorkLogType.name == work_type.name).first()
    if existing_type:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="å·¥ä½œç±»å‹åç§°å·²å­˜åœ¨"
        )
    
    db_work_type = WorkLogType(
        id=str(uuid.uuid4()),
        **work_type.dict()
    )
    
    db.add(db_work_type)
    db.commit()
    db.refresh(db_work_type)
    
    return db_work_type

# ==================== ç»Ÿè®¡å’ŒæŠ¥è¡¨ ====================

@router.get("/weeks/{week_id}/statistics", response_model=WorkWeekStatistics)
async def get_work_week_statistics(
    week_id: str,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """è·å–å·¥ä½œå‘¨ç»Ÿè®¡ä¿¡æ¯"""
    
    work_week = db.query(WorkWeek).filter(WorkWeek.id == week_id).first()
    if not work_week:
        raise HTTPException(status_code=404, detail="å·¥ä½œå‘¨ä¸å­˜åœ¨")
    
    # è·å–æ‰€æœ‰æ¡ç›®ï¼ŒæŒ‰ç”¨æˆ·åˆ†ç»„
    entries = db.query(WorkLogEntry).options(
        joinedload(WorkLogEntry.user)
    ).filter(WorkLogEntry.work_week_id == week_id).all()
    
    # æŒ‰ç”¨æˆ·ç»Ÿè®¡
    user_stats = {}
    for entry in entries:
        user_id = entry.user_id
        if user_id not in user_stats:
            user_stats[user_id] = {
                'user_id': user_id,
                'user_name': getattr(entry.user, 'real_name', None) or getattr(entry.user, 'username', ''),
                'entries': [],
                'total_planned_hours': 0,
                'total_actual_hours': 0,
                'completion_rates': [],
                'status_count': {'pending': 0, 'submitted': 0, 'approved': 0, 'rejected': 0},
                'work_type_hours': {}  # æŒ‰å·¥ä½œç±»å‹ç»Ÿè®¡å·¥æ—¶
            }
        
        user_stats[user_id]['entries'].append(entry)
        user_stats[user_id]['total_planned_hours'] += entry.planned_hours
        if entry.actual_hours:
            user_stats[user_id]['total_actual_hours'] += entry.actual_hours
            # æŒ‰å·¥ä½œç±»å‹ç»Ÿè®¡å®é™…å·¥æ—¶
            work_type = entry.work_type or 'å…¶ä»–'
            if work_type not in user_stats[user_id]['work_type_hours']:
                user_stats[user_id]['work_type_hours'][work_type] = 0
            user_stats[user_id]['work_type_hours'][work_type] += entry.actual_hours
        user_stats[user_id]['completion_rates'].append(entry.completion_rate)
        user_stats[user_id]['status_count'][entry.status] += 1
    
    # ç”Ÿæˆç”¨æˆ·æ±‡æ€»
    user_summaries = []
    for user_id, stats in user_stats.items():
        avg_completion = sum(stats['completion_rates']) / len(stats['completion_rates']) if stats['completion_rates'] else 0
        submitted_days = stats['status_count']['submitted'] + stats['status_count']['approved']
        
        summary_dict = {
            'work_week_id': week_id,
            'user_id': user_id,
            'user_name': stats['user_name'],
            'total_planned_hours': stats['total_planned_hours'],
            'total_actual_hours': stats['total_actual_hours'],
            'average_completion_rate': avg_completion,
            'submitted_days': submitted_days,
            'total_days': len(stats['entries']),
            'status_summary': stats['status_count'],
            'total_entries': len(stats['entries']),
            'work_type_hours': stats['work_type_hours']
        }
        user_summaries.append(WorkWeekSummary(**summary_dict))
    
    # æ•´ä½“ç»Ÿè®¡
    total_entries = len(entries)
    submitted_entries = len([e for e in entries if e.status in ['submitted', 'approved']])
    overall_completion = (submitted_entries / total_entries * 100) if total_entries > 0 else 0
    
    overall_stats = {
        'total_users': len(user_stats),
        'total_entries': total_entries,
        'submitted_entries': submitted_entries,
        'completion_rate': overall_completion,
        'total_planned_hours': sum(e.planned_hours for e in entries),
        'total_actual_hours': sum(e.actual_hours or 0 for e in entries)
    }
    
    return WorkWeekStatistics(
        work_week=work_week,
        user_summaries=user_summaries,
        overall_stats=overall_stats
    )

# ==================== è¾…åŠ©å‡½æ•° ====================

async def _create_default_entries_for_week(db: Session, work_week: WorkWeek):
    """ä¸ºå·¥ä½œå‘¨åˆ›å»ºé»˜è®¤çš„å·¥ä½œæ—¥å¿—æ¡ç›®"""
    
    # è·å–æ‰€æœ‰æ´»è·ƒç”¨æˆ·
    active_users = db.query(User).filter(User.status == "active").all()
    
    # ä¸ºæ¯ä¸ªç”¨æˆ·åˆ›å»º5å¤©çš„å·¥ä½œæ—¥å¿—æ¡ç›®
    for user in active_users:
        for i in range(5):  # å‘¨ä¸€åˆ°å‘¨äº”
            work_date = work_week.week_start_date + timedelta(days=i)
            day_of_week = i + 1  # 1=å‘¨ä¸€, 5=å‘¨äº”
            
            entry = WorkLogEntry(
                id=str(uuid.uuid4()),
                work_week_id=work_week.id,
                user_id=user.id,
                work_date=work_date,
                day_of_week=day_of_week,
                status="pending"
            )
            db.add(entry)
    
    db.commit()

async def _generate_entries_for_specific_users(db: Session, work_week: WorkWeek, user_ids: list[str]):
    from app.models.user import User
    # ä»…ä¸ºæŒ‡å®šç”¨æˆ·ç”Ÿæˆ 5 å¤© pending æ¡ç›®
    for user_id in user_ids:
        for i in range(5):
            work_date = work_week.week_start_date + timedelta(days=i)
            day_of_week = i + 1
            entry = WorkLogEntry(
                id=str(uuid.uuid4()),
                work_week_id=work_week.id,
                user_id=user_id,
                work_date=work_date,
                day_of_week=day_of_week,
                status="pending"
            )
            db.add(entry)
    db.commit()

@router.post("/weeks/{week_id}/generate-entries")
async def generate_entries_for_week(
    week_id: str,
    user_ids: Optional[List[str]] = Body(None, embed=True),
    db: Session = Depends(get_db),
    current_user: User = Depends(require_permission("WorkLogManagement"))
):
    """ä¸ºæŒ‡å®šç”¨æˆ·ç”Ÿæˆå·¥ä½œå‘¨æ¡ç›®
    
    è¯·æ±‚ä½“ç¤ºä¾‹:
    {
        "user_ids": ["user1", "user2", "user3"]
    }
    """
    
    work_week = db.query(WorkWeek).filter(WorkWeek.id == week_id).first()
    if not work_week:
        raise HTTPException(status_code=404, detail="å·¥ä½œå‘¨ä¸å­˜åœ¨")
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šç”¨æˆ·ï¼Œåˆ™ä¸ºæ‰€æœ‰æ´»è·ƒç”¨æˆ·ç”Ÿæˆ
    if not user_ids:
        users = db.query(User).filter(User.status == "active").all()
        user_ids = [user.id for user in users]
    
    # ä¸ºæŒ‡å®šç”¨æˆ·ç”Ÿæˆæ¡ç›®
    generated_count = 0
    for user_id in user_ids:
        for i in range(5):  # å‘¨ä¸€åˆ°å‘¨äº”
            work_date = work_week.week_start_date + timedelta(days=i)
            day_of_week = i + 1
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            existing = db.query(WorkLogEntry).filter(
                WorkLogEntry.work_week_id == week_id,
                WorkLogEntry.user_id == user_id,
                WorkLogEntry.work_date == work_date
            ).first()
            
            if not existing:
                entry = WorkLogEntry(
                    id=str(uuid.uuid4()),
                    work_week_id=week_id,
                    user_id=user_id,
                    work_date=work_date,
                    day_of_week=day_of_week,
                    status="pending"
                )
                db.add(entry)
                generated_count += 1
    
    db.commit()
    
    return {"message": f"å·²ç”Ÿæˆ {generated_count} ä¸ªå·¥ä½œæ—¥å¿—æ¡ç›®"}


# ==================== å·¥ä½œå‘¨å¯¼å‡º ====================

@router.get("/weeks/{week_id}/export")
async def export_work_week_report(
    week_id: str,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    å¯¼å‡ºå·¥ä½œå‘¨ç»Ÿè®¡æŠ¥å‘ŠPDF
    """
    try:
        logger.info(f"ğŸ“Š [WorkLogExport] å¼€å§‹ç”Ÿæˆå·¥ä½œå‘¨æŠ¥å‘Š: ç”¨æˆ·={current_user.username}, å·¥ä½œå‘¨ID={week_id}")
        
        # 1. æŸ¥è¯¢å·¥ä½œå‘¨ä¿¡æ¯
        work_week = db.query(WorkWeek).filter(WorkWeek.id == week_id).first()
        if not work_week:
            raise HTTPException(status_code=404, detail="å·¥ä½œå‘¨ä¸å­˜åœ¨")
        
        # 2. è·å–å·¥ä½œå‘¨ç»Ÿè®¡æ•°æ®ï¼ˆå¤ç”¨ç°æœ‰çš„ç»Ÿè®¡æ¥å£é€»è¾‘ï¼‰
        entries = db.query(WorkLogEntry).filter(
            WorkLogEntry.work_week_id == week_id
        ).options(
            joinedload(WorkLogEntry.user)
        ).all()
        
        logger.info(f"ğŸ“‹ [WorkLogExport] æŸ¥è¯¢åˆ°å·¥ä½œæ—¥å¿—æ¡ç›®æ•°: {len(entries)}")
        
        # 3. å‡†å¤‡å·¥ä½œå‘¨ä¿¡æ¯
        status_text_map = {
            'active': 'è¿›è¡Œä¸­',
            'archived': 'å·²å½’æ¡£',
            'draft': 'è‰ç¨¿'
        }
        
        # ä»æ—¥æœŸä¸­æå–å¹´ä»½å’Œå‘¨æ•°
        year = work_week.week_start_date.year
        # è®¡ç®—ISOå‘¨æ•°
        week_number = work_week.week_start_date.isocalendar()[1]
        
        work_week_info = {
            'title': work_week.title,
            'week_start_date': work_week.week_start_date.strftime('%Y-%m-%d'),
            'week_end_date': work_week.week_end_date.strftime('%Y-%m-%d'),
            'year': year,
            'week_number': week_number,
            'status': work_week.status,
            'status_text': status_text_map.get(work_week.status, 'æœªçŸ¥')
        }
        
        # 4. è®¡ç®—æ•´ä½“ç»Ÿè®¡
        user_ids = set()
        total_actual_hours = 0.0
        work_type_hours_total = {}
        
        for entry in entries:
            if entry.user_id:
                user_ids.add(entry.user_id)
            if entry.actual_hours:
                total_actual_hours += entry.actual_hours
                
                # ç»Ÿè®¡å·¥ä½œç±»å‹å·¥æ—¶ï¼ˆwork_type æ˜¯å­—ç¬¦ä¸²åˆ—ï¼Œä¸æ˜¯å…³ç³»ï¼‰
                work_type_name = entry.work_type or 'æœªåˆ†ç±»'
                work_type_hours_total[work_type_name] = work_type_hours_total.get(work_type_name, 0) + entry.actual_hours
        
        total_users = len(user_ids)
        total_planned_hours = total_users * 40  # æ¯äºº40å°æ—¶
        efficiency = round((total_actual_hours / total_planned_hours) * 100, 1) if total_planned_hours > 0 else 0
        
        overall_stats = {
            'total_users': total_users,
            'total_planned_hours': total_planned_hours,
            'total_actual_hours': round(total_actual_hours, 1),
            'efficiency': efficiency
        }
        
        # 5. è®¡ç®—ç”¨æˆ·è¯¦ç»†ç»Ÿè®¡
        user_stats_map = {}
        for entry in entries:
            if not entry.user_id:
                continue
            
            user_id = entry.user_id
            if user_id not in user_stats_map:
                user_name = entry.user.real_name if entry.user and entry.user.real_name else (entry.user.username if entry.user else 'æœªçŸ¥ç”¨æˆ·')
                user_stats_map[user_id] = {
                    'user_id': user_id,
                    'user_name': user_name,
                    'total_actual_hours': 0.0,
                    'work_type_hours': {},
                    'entries_count': 0
                }
            
            if entry.actual_hours:
                user_stats_map[user_id]['total_actual_hours'] += entry.actual_hours
                
                work_type_name = entry.work_type or 'æœªåˆ†ç±»'
                user_stats_map[user_id]['work_type_hours'][work_type_name] = \
                    user_stats_map[user_id]['work_type_hours'].get(work_type_name, 0) + entry.actual_hours
            
            user_stats_map[user_id]['entries_count'] += 1
        
        # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æ’åº
        user_summaries = sorted(
            [
                {
                    'user_name': stats['user_name'],
                    'total_actual_hours': round(stats['total_actual_hours'], 1),
                    'work_type_hours': {k: round(v, 1) for k, v in stats['work_type_hours'].items()},
                    'entries_count': stats['entries_count']
                }
                for stats in user_stats_map.values()
            ],
            key=lambda x: x['total_actual_hours'],
            reverse=True
        )
        
        # 6. å·¥ä½œç±»å‹ç»Ÿè®¡ï¼ˆå››èˆäº”å…¥ï¼‰
        work_type_stats = {k: round(v, 1) for k, v in work_type_hours_total.items()}
        
        logger.info(f"ğŸ“Š [WorkLogExport] ç»Ÿè®¡å®Œæˆ: ç”¨æˆ·æ•°={total_users}, æ€»å·¥æ—¶={total_actual_hours}h")
        
        # 7. ç”ŸæˆPDF
        pdf_buffer = work_log_pdf_service.generate_work_week_report(
            work_week_info=work_week_info,
            overall_stats=overall_stats,
            user_summaries=user_summaries,
            work_type_stats=work_type_stats
        )
        
        # 8. æ„å»ºæ–‡ä»¶å
        filename = f"{work_week.title}_ç»Ÿè®¡æŠ¥å‘Š.pdf"
        filename = filename.encode('utf-8').decode('latin1')  # å¤„ç†ä¸­æ–‡æ–‡ä»¶å
        
        logger.info(f"âœ… [WorkLogExport] æŠ¥å‘Šç”ŸæˆæˆåŠŸ: {filename}")
        
        # 9. è¿”å›PDFæ–‡ä»¶
        return StreamingResponse(
            pdf_buffer,
            media_type="application/pdf",
            headers={
                "Content-Disposition": f"attachment; filename*=UTF-8''{filename}"
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [WorkLogExport] ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {str(e)}"
        )


@router.get("/export")
async def export_work_log_report(
    report_type: str,
    week_id: Optional[str] = None,
    year: Optional[int] = None,
    month: Optional[int] = None,
    quarter: Optional[int] = None,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    ç»Ÿä¸€çš„å·¥ä½œæ—¥å¿—å¯¼å‡ºç«¯ç‚¹
    - report_type: single (å•ä¸ªå·¥ä½œå‘¨), monthly (æœˆåº¦), quarterly (å­£åº¦), yearly (å¹´åº¦)
    - week_id: å•ä¸ªå·¥ä½œå‘¨ID (report_type=singleæ—¶ä½¿ç”¨)
    - year: å¹´ä»½
    - month: æœˆä»½ (report_type=monthlyæ—¶ä½¿ç”¨)
    - quarter: å­£åº¦ (report_type=quarterlyæ—¶ä½¿ç”¨)
    """
    try:
        logger.info(f"ğŸ“Š [WorkLogExport] å¼€å§‹ç”Ÿæˆ{report_type}æŠ¥å‘Š: ç”¨æˆ·={current_user.username}")
        
        if report_type == 'single':
            # å•ä¸ªå·¥ä½œå‘¨ - å¤ç”¨åŸæœ‰é€»è¾‘
            if not week_id:
                raise HTTPException(status_code=400, detail="ç¼ºå°‘ week_id å‚æ•°")
            return await export_work_week_report(week_id, db, current_user)
        
        # æœˆåº¦/å­£åº¦/å¹´åº¦æŠ¥å‘Š
        year = year or datetime.now().year
        
        # ç¡®å®šæ—¥æœŸèŒƒå›´
        if report_type == 'monthly':
            if not month:
                month = datetime.now().month
            start_date = date(year, month, 1)
            # ä¸‹ä¸ªæœˆçš„ç¬¬ä¸€å¤©
            if month == 12:
                end_date = date(year + 1, 1, 1)
            else:
                end_date = date(year, month + 1, 1)
            period_name = f"{year}å¹´{month}æœˆ"
            
        elif report_type == 'quarterly':
            if not quarter or quarter not in [1, 2, 3, 4]:
                quarter = (datetime.now().month - 1) // 3 + 1
            start_month = (quarter - 1) * 3 + 1
            end_month = start_month + 3
            start_date = date(year, start_month, 1)
            if end_month > 12:
                end_date = date(year + 1, end_month - 12, 1)
            else:
                end_date = date(year, end_month, 1)
            period_name = f"{year}å¹´ç¬¬{quarter}å­£åº¦"
            
        elif report_type == 'yearly':
            start_date = date(year, 1, 1)
            end_date = date(year + 1, 1, 1)
            period_name = f"{year}å¹´åº¦"
        
        else:
            raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„æŠ¥å‘Šç±»å‹: {report_type}")
        
        logger.info(f"ğŸ“… [WorkLogExport] æ—¥æœŸèŒƒå›´: {start_date} ~ {end_date}")
        
        # æŸ¥è¯¢è¯¥æ—¶é—´æ®µå†…çš„æ‰€æœ‰å·¥ä½œå‘¨
        work_weeks = db.query(WorkWeek).filter(
            and_(
                WorkWeek.week_start_date >= start_date,
                WorkWeek.week_start_date < end_date
            )
        ).order_by(WorkWeek.week_start_date).all()
        
        if not work_weeks:
            raise HTTPException(status_code=404, detail=f"{period_name}æ²¡æœ‰å·¥ä½œå‘¨æ•°æ®")
        
        logger.info(f"ğŸ“‹ [WorkLogExport] æ‰¾åˆ° {len(work_weeks)} ä¸ªå·¥ä½œå‘¨")
        
        # æŸ¥è¯¢æ‰€æœ‰å·¥ä½œæ—¥å¿—æ¡ç›®
        week_ids = [ww.id for ww in work_weeks]
        entries = db.query(WorkLogEntry).filter(
            WorkLogEntry.work_week_id.in_(week_ids)
        ).options(
            joinedload(WorkLogEntry.user)
        ).all()
        
        logger.info(f"ğŸ“‹ [WorkLogExport] æŸ¥è¯¢åˆ°å·¥ä½œæ—¥å¿—æ¡ç›®æ•°: {len(entries)}")
        
        # å‡†å¤‡æŠ¥å‘Šä¿¡æ¯
        work_week_info = {
            'title': f"{period_name}å·¥ä½œæ—¥å¿—ç»Ÿè®¡æŠ¥å‘Š",
            'week_start_date': start_date.strftime('%Y-%m-%d'),
            'week_end_date': (end_date - timedelta(days=1)).strftime('%Y-%m-%d'),
            'year': year,
            'week_number': f"{len(work_weeks)}ä¸ªå·¥ä½œå‘¨",
            'status': 'aggregated',
            'status_text': f'èšåˆæŠ¥å‘Šï¼ˆ{len(work_weeks)}ä¸ªå·¥ä½œå‘¨ï¼‰'
        }
        
        # è®¡ç®—æ•´ä½“ç»Ÿè®¡
        user_ids = set()
        total_actual_hours = 0.0
        work_type_hours_total = {}
        
        for entry in entries:
            if entry.user_id:
                user_ids.add(entry.user_id)
            if entry.actual_hours:
                total_actual_hours += entry.actual_hours
                
                work_type_name = entry.work_type or 'æœªåˆ†ç±»'
                work_type_hours_total[work_type_name] = work_type_hours_total.get(work_type_name, 0) + entry.actual_hours
        
        total_users = len(user_ids)
        # è®¡åˆ’å·¥æ—¶ = ç”¨æˆ·æ•° Ã— å·¥ä½œå‘¨æ•° Ã— 40å°æ—¶
        total_planned_hours = total_users * len(work_weeks) * 40
        efficiency = round((total_actual_hours / total_planned_hours) * 100, 1) if total_planned_hours > 0 else 0
        
        overall_stats = {
            'total_users': total_users,
            'total_planned_hours': total_planned_hours,
            'total_actual_hours': round(total_actual_hours, 1),
            'efficiency': efficiency
        }
        
        # è®¡ç®—ç”¨æˆ·è¯¦ç»†ç»Ÿè®¡
        user_stats_map = {}
        for entry in entries:
            if not entry.user_id:
                continue
            
            user_id = entry.user_id
            if user_id not in user_stats_map:
                user_name = entry.user.real_name if entry.user and entry.user.real_name else (entry.user.username if entry.user else 'æœªçŸ¥ç”¨æˆ·')
                user_stats_map[user_id] = {
                    'user_id': user_id,
                    'user_name': user_name,
                    'total_actual_hours': 0.0,
                    'work_type_hours': {},
                    'entries_count': 0
                }
            
            if entry.actual_hours:
                user_stats_map[user_id]['total_actual_hours'] += entry.actual_hours
                
                work_type_name = entry.work_type or 'æœªåˆ†ç±»'
                user_stats_map[user_id]['work_type_hours'][work_type_name] = \
                    user_stats_map[user_id]['work_type_hours'].get(work_type_name, 0) + entry.actual_hours
            
            user_stats_map[user_id]['entries_count'] += 1
        
        # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æ’åº
        user_summaries = sorted(
            [
                {
                    'user_name': stats['user_name'],
                    'total_actual_hours': round(stats['total_actual_hours'], 1),
                    'work_type_hours': {k: round(v, 1) for k, v in stats['work_type_hours'].items()},
                    'entries_count': stats['entries_count']
                }
                for stats in user_stats_map.values()
            ],
            key=lambda x: x['total_actual_hours'],
            reverse=True
        )
        
        # å·¥ä½œç±»å‹ç»Ÿè®¡
        work_type_stats = {k: round(v, 1) for k, v in work_type_hours_total.items()}
        
        logger.info(f"ğŸ“Š [WorkLogExport] ç»Ÿè®¡å®Œæˆ: {len(work_weeks)}ä¸ªå·¥ä½œå‘¨, {total_users}ä¸ªç”¨æˆ·, æ€»å·¥æ—¶={total_actual_hours}h")
        
        # ç”ŸæˆPDF
        pdf_buffer = work_log_pdf_service.generate_work_week_report(
            work_week_info=work_week_info,
            overall_stats=overall_stats,
            user_summaries=user_summaries,
            work_type_stats=work_type_stats
        )
        
        # æ„å»ºæ–‡ä»¶å
        filename = f"{period_name}_å·¥ä½œæ—¥å¿—ç»Ÿè®¡æŠ¥å‘Š.pdf"
        filename = filename.encode('utf-8').decode('latin1')
        
        logger.info(f"âœ… [WorkLogExport] æŠ¥å‘Šç”ŸæˆæˆåŠŸ: {filename}")
        
        # è¿”å›PDFæ–‡ä»¶
        return StreamingResponse(
            pdf_buffer,
            media_type="application/pdf",
            headers={
                "Content-Disposition": f"attachment; filename*=UTF-8''{filename}"
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [WorkLogExport] ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {str(e)}"
        )
