# ğŸš€ Redis ä¼˜åŒ–æ–¹æ¡ˆ - é¡¹ç›®ç®¡ç†ç³»ç»Ÿå…¨é¢æé€Ÿ

## ğŸ“‹ ç›®å½•

1. [ä¸ºä»€ä¹ˆéœ€è¦Redis](#ä¸ºä»€ä¹ˆéœ€è¦redis)
2. [Redisåº”ç”¨åœºæ™¯](#redisåº”ç”¨åœºæ™¯)
3. [å®æ–½æ–¹æ¡ˆ](#å®æ–½æ–¹æ¡ˆ)
4. [ä»£ç å®ç°](#ä»£ç å®ç°)
5. [æ€§èƒ½å¯¹æ¯”](#æ€§èƒ½å¯¹æ¯”)
6. [éƒ¨ç½²æŒ‡å—](#éƒ¨ç½²æŒ‡å—)

---

## ğŸ¯ ä¸ºä»€ä¹ˆéœ€è¦Redis

### å½“å‰é—®é¢˜

- âœ… **æ•°æ®åº“ç´¢å¼•å·²ä¼˜åŒ–** - æŸ¥è¯¢é€Ÿåº¦æå‡ 60-80%
- âš ï¸ **é‡å¤æŸ¥è¯¢é¢‘ç¹** - ç›¸åŒæ•°æ®è¢«å¤šæ¬¡æŸ¥è¯¢
- âš ï¸ **å®æ—¶æ€§è¦æ±‚é«˜** - é€šçŸ¥ã€ç»Ÿè®¡éœ€è¦å¿«é€Ÿå“åº”
- âš ï¸ **å¹¶å‘å‹åŠ›** - å¤šç”¨æˆ·åŒæ—¶è®¿é—®æ—¶æ•°æ®åº“å‹åŠ›å¤§

### Redisä¼˜åŠ¿

- âš¡ **è¶…å¿«å“åº”** - å†…å­˜æ“ä½œï¼Œ<10mså“åº”æ—¶é—´
- ğŸ”„ **å‡è½»æ•°æ®åº“è´Ÿè½½** - 80%çš„è¯»è¯·æ±‚ç”±Rediså¤„ç†
- ğŸ“Š **ä¸°å¯Œæ•°æ®ç»“æ„** - String/Hash/List/Set/ZSet é€‚ç”¨ä¸åŒåœºæ™¯
- ğŸ”” **åŸç”Ÿæ”¯æŒå‘å¸ƒè®¢é˜…** - å®æ—¶é€šçŸ¥ç³»ç»Ÿ
- â° **è‡ªåŠ¨è¿‡æœŸ** - æ— éœ€æ‰‹åŠ¨æ¸…ç†ç¼“å­˜

---

## ğŸ¨ Redisåº”ç”¨åœºæ™¯

### ä¼˜å…ˆçº§1 (å¿…é¡»å®æ–½) - é¢„æœŸæå‡ 80%+

#### 1.1 ä»»åŠ¡åˆ—è¡¨ç¼“å­˜

**åœºæ™¯**: ä»»åŠ¡æ± é¡µé¢ã€æˆ‘çš„ä»»åŠ¡ã€é¡¹ç›®ä»»åŠ¡åˆ—è¡¨

**ç—›ç‚¹**: 450+ä»»åŠ¡æ—¶ï¼Œæ¯æ¬¡åˆ·æ–°éƒ½æŸ¥è¯¢æ•°æ®åº“

**æ–¹æ¡ˆ**:

```
ç¼“å­˜Keyè®¾è®¡:
- tasks:list:all:{page}:{size}:{filters_hash}
- tasks:list:project:{project_id}:{page}:{size}
- tasks:list:user:{user_id}:{status}
- tasks:detail:{task_id}

è¿‡æœŸæ—¶é—´: 5åˆ†é’Ÿ
ç¼“å­˜å‘½ä¸­ç‡: 70-80%
æ€§èƒ½æå‡: 3ç§’ â†’ 0.05ç§’ (æå‡ 98%)
```

**è§¦å‘æ¸…é™¤**:

- åˆ›å»ºä»»åŠ¡ â†’ æ¸…é™¤ `tasks:list:*`
- æ›´æ–°ä»»åŠ¡ â†’ æ¸…é™¤ `tasks:list:*` + `tasks:detail:{id}`
- åˆ é™¤ä»»åŠ¡ â†’ æ¸…é™¤ `tasks:list:*` + `tasks:detail:{id}`

---

#### 1.2 é¡¹ç›®åˆ—è¡¨ç¼“å­˜

**åœºæ™¯**: é¡¹ç›®ç®¡ç†ã€é¡¹ç›®ä¸‹æ‹‰é€‰æ‹©

**ç—›ç‚¹**: é¡¹ç›®åˆ—è¡¨åœ¨å¤šä¸ªé¡µé¢è¢«é¢‘ç¹æŸ¥è¯¢

**æ–¹æ¡ˆ**:

```
ç¼“å­˜Key:
- projects:list:active
- projects:list:all
- projects:detail:{project_id}
- projects:stats:{project_id}

è¿‡æœŸæ—¶é—´: 10åˆ†é’Ÿ
ç¼“å­˜å‘½ä¸­ç‡: 85-90%
æ€§èƒ½æå‡: 500ms â†’ 10ms (æå‡ 98%)
```

---

#### 1.3 ç”¨æˆ·ä¿¡æ¯ç¼“å­˜

**åœºæ™¯**: ç”¨æˆ·åæ˜¾ç¤ºã€æƒé™æ£€æŸ¥ã€ä¸‹æ‹‰é€‰æ‹©

**ç—›ç‚¹**: æ¯æ¬¡æ¸²æŸ“è¡¨æ ¼éƒ½æŸ¥è¯¢ç”¨æˆ·ä¿¡æ¯

**æ–¹æ¡ˆ**:

```
ç¼“å­˜Key:
- user:info:{user_id}           # Hash: {id, name, role, department}
- user:list:active              # List: æ‰€æœ‰æ´»è·ƒç”¨æˆ·
- user:permissions:{user_id}    # Set: ç”¨æˆ·æƒé™é›†åˆ

è¿‡æœŸæ—¶é—´: 30åˆ†é’Ÿ
ç¼“å­˜å‘½ä¸­ç‡: 95%+
æ€§èƒ½æå‡: 200ms â†’ 5ms (æå‡ 97%)
```

---

### ä¼˜å…ˆçº§2 (å¼ºçƒˆæ¨è) - é¢„æœŸæå‡ 60%+

#### 2.1 ç»Ÿè®¡æ•°æ®ç¼“å­˜

**åœºæ™¯**: é¡¹ç›®ä»ªè¡¨æ¿ã€ç»©æ•ˆç»Ÿè®¡ã€å·¥ä½œæ—¥å¿—ç»Ÿè®¡

**ç—›ç‚¹**: å¤æ‚ç»Ÿè®¡æŸ¥è¯¢è€—æ—¶é•¿ï¼ˆ3-5ç§’ï¼‰

**æ–¹æ¡ˆ**:

```
ç¼“å­˜Key:
- stats:dashboard:user:{user_id}            # ä¸ªäººä»ªè¡¨æ¿
- stats:dashboard:project:{project_id}      # é¡¹ç›®ä»ªè¡¨æ¿
- stats:performance:team:{date}             # å›¢é˜Ÿç»©æ•ˆ
- stats:performance:personal:{user_id}      # ä¸ªäººç»©æ•ˆ
- stats:worklog:weekly:{week}               # å‘¨æŠ¥ç»Ÿè®¡

è¿‡æœŸæ—¶é—´: 15åˆ†é’Ÿ (ç»Ÿè®¡æ•°æ®å¯å®¹å¿å»¶è¿Ÿ)
ç¼“å­˜å‘½ä¸­ç‡: 60-70%
æ€§èƒ½æå‡: 3ç§’ â†’ 0.5ç§’ (æå‡ 83%)
```

**ç‰¹æ®Šå¤„ç†**:

```python
# åå°ä»»åŠ¡æ¯15åˆ†é’Ÿé¢„çƒ­ç¼“å­˜
async def warm_up_dashboard_cache():
    for user in active_users:
        calculate_and_cache_dashboard(user.id)
```

---

#### 2.2 æ–‡ç« /çŸ¥è¯†åº“ç¼“å­˜

**åœºæ™¯**: ä¼šè®®è®°å½•ã€æ¨¡å‹æµ‹è¯•ã€å›¢é˜Ÿåä½œæ–‡ç« 

**ç—›ç‚¹**: å¯Œæ–‡æœ¬å†…å®¹å¤§ï¼ŒåŠ è½½æ…¢

**æ–¹æ¡ˆ**:

```
ç¼“å­˜Key:
- article:detail:{article_id}       # Hash: æ–‡ç« å®Œæ•´ä¿¡æ¯
- article:list:{type}:{page}        # List: æ–‡ç« åˆ—è¡¨
- article:tree:{type}               # String: å¯¼èˆªæ ‘JSON
- article:history:{article_id}      # List: ç¼–è¾‘å†å²

è¿‡æœŸæ—¶é—´:
- detail: 20åˆ†é’Ÿ
- list: 10åˆ†é’Ÿ
- tree: 30åˆ†é’Ÿ

æ€§èƒ½æå‡: 800ms â†’ 50ms (æå‡ 94%)
```

---

#### 2.3 å®æ—¶é€šçŸ¥ç³»ç»Ÿ

**åœºæ™¯**: ä»»åŠ¡å®¡æ ¸é€šçŸ¥ã€ç³»ç»Ÿæ¶ˆæ¯

**å½“å‰é—®é¢˜**: ä½¿ç”¨WebSocketè½®è¯¢ï¼Œæ•ˆç‡ä½

**æ–¹æ¡ˆ**: ä½¿ç”¨ Redis Pub/Sub

```
é¢‘é“è®¾è®¡:
- notify:user:{user_id}          # ç”¨æˆ·ä¸ªäººé€šçŸ¥
- notify:role:{role}             # è§’è‰²é€šçŸ¥ï¼ˆå¦‚å®¡æ ¸å‘˜ï¼‰
- notify:global                  # å…¨å±€å¹¿æ’­

ä¼˜åŠ¿:
- å®æ—¶æ¨é€ï¼Œæ— å»¶è¿Ÿ
- å‡å°‘WebSocketè¿æ¥æ•°
- æ”¯æŒæ¶ˆæ¯æŒä¹…åŒ–ï¼ˆä½¿ç”¨Streamï¼‰
```

---

### ä¼˜å…ˆçº§3 (ä¼˜åŒ–ä½“éªŒ) - é¢„æœŸæå‡ 40%+

#### 3.1 ä¼šè¯ç®¡ç†

**åœºæ™¯**: ç”¨æˆ·ç™»å½•çŠ¶æ€ã€TokenéªŒè¯

**å½“å‰**: JWTå­˜å‚¨åœ¨localStorageï¼Œæ¯æ¬¡è¯·æ±‚éªŒè¯

**ä¼˜åŒ–**:

```
ç¼“å­˜Key:
- session:{token}                # Hash: ç”¨æˆ·ä¼šè¯ä¿¡æ¯
- session:user:{user_id}         # Set: ç”¨æˆ·çš„æ‰€æœ‰ä¼šè¯

ä¼˜åŠ¿:
- å¿«é€ŸéªŒè¯Tokenï¼ˆä¸æŸ¥æ•°æ®åº“ï¼‰
- æ”¯æŒå¼ºåˆ¶è¸¢å‡ºç”¨æˆ·
- æ”¯æŒåœ¨çº¿ç”¨æˆ·ç»Ÿè®¡
```

---

#### 3.2 æœç´¢ç»“æœç¼“å­˜

**åœºæ™¯**: ä»»åŠ¡æœç´¢ã€æ–‡ç« æœç´¢ã€ç”¨æˆ·æœç´¢

**æ–¹æ¡ˆ**:

```
ç¼“å­˜Key:
- search:tasks:{query_hash}
- search:articles:{query_hash}

è¿‡æœŸæ—¶é—´: 5åˆ†é’Ÿ
é€‚ç”¨: çƒ­é—¨æœç´¢è¯
```

---

#### 3.3 æ–‡ä»¶ä¸Šä¼ é”

**åœºæ™¯**: é˜²æ­¢é‡å¤ä¸Šä¼ ã€å¤§æ–‡ä»¶ä¸Šä¼ è¿›åº¦

**æ–¹æ¡ˆ**:

```
ç¼“å­˜Key:
- upload:lock:{file_md5}         # ä¸Šä¼ é”
- upload:progress:{upload_id}    # ä¸Šä¼ è¿›åº¦

ä½¿ç”¨: SET NX å®ç°åˆ†å¸ƒå¼é”
```

---

#### 3.4 é™æµæ§åˆ¶

**åœºæ™¯**: APIè¯·æ±‚é™æµã€é˜²æ­¢æ¶æ„æ”»å‡»

**æ–¹æ¡ˆ**:

```
ç¼“å­˜Key:
- ratelimit:ip:{ip}:{endpoint}
- ratelimit:user:{user_id}:{endpoint}

å®ç°: æ»‘åŠ¨çª—å£ç®—æ³•
é™åˆ¶: æ¯ç”¨æˆ·æ¯åˆ†é’Ÿ100æ¬¡è¯·æ±‚
```

---

## ğŸ› ï¸ å®æ–½æ–¹æ¡ˆ

### é˜¶æ®µ1: åŸºç¡€è®¾æ–½ (1å¤©)

```bash
# 1. å®‰è£…Redis
# Ubuntu/Debian
sudo apt update
sudo apt install redis-server

# macOS
brew install redis

# Windows
# ä¸‹è½½ https://github.com/microsoftarchive/redis/releases

# 2. å¯åŠ¨Redis
redis-server

# 3. æµ‹è¯•è¿æ¥
redis-cli ping
# åº”è¯¥è¿”å›: PONG
```

**Pythonä¾èµ–** (å·²åœ¨requirements.txt):

```
redis==5.0.1  âœ… å·²å®‰è£…
```

---

### é˜¶æ®µ2: ç¼“å­˜æœåŠ¡ (2å¤©)

åˆ›å»ºç»Ÿä¸€çš„ç¼“å­˜æœåŠ¡å±‚ï¼š

```python
# backend/app/services/cache_service.py
import redis
import json
import hashlib
from typing import Optional, Any, List
from datetime import timedelta
from functools import wraps
import logging

logger = logging.getLogger(__name__)

class CacheService:
    def __init__(self):
        self.redis_client = redis.Redis(
            host='localhost',
            port=6379,
            db=0,
            decode_responses=True,
            socket_connect_timeout=2,
            socket_timeout=2
        )
        self.enabled = self._check_redis_available()
        self.default_ttl = 300  # 5åˆ†é’Ÿ

    def _check_redis_available(self) -> bool:
        """æ£€æŸ¥Redisæ˜¯å¦å¯ç”¨"""
        try:
            self.redis_client.ping()
            logger.info("âœ… Redisè¿æ¥æˆåŠŸ")
            return True
        except Exception as e:
            logger.warning(f"âš ï¸ Redisä¸å¯ç”¨: {e}")
            return False

    # ==================== åŸºç¡€æ“ä½œ ====================

    def get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜"""
        if not self.enabled:
            return None
        try:
            data = self.redis_client.get(key)
            if data:
                return json.loads(data)
            return None
        except Exception as e:
            logger.error(f"Redis GETå¤±è´¥ {key}: {e}")
            return None

    def set(self, key: str, value: Any, expire: int = None):
        """è®¾ç½®ç¼“å­˜"""
        if not self.enabled:
            return False
        try:
            expire = expire or self.default_ttl
            self.redis_client.setex(
                key,
                expire,
                json.dumps(value, ensure_ascii=False, default=str)
            )
            return True
        except Exception as e:
            logger.error(f"Redis SETå¤±è´¥ {key}: {e}")
            return False

    def delete(self, key: str):
        """åˆ é™¤å•ä¸ªkey"""
        if not self.enabled:
            return
        try:
            self.redis_client.delete(key)
        except Exception as e:
            logger.error(f"Redis DELETEå¤±è´¥ {key}: {e}")

    def delete_pattern(self, pattern: str):
        """æ‰¹é‡åˆ é™¤åŒ¹é…çš„key"""
        if not self.enabled:
            return
        try:
            keys = self.redis_client.keys(pattern)
            if keys:
                self.redis_client.delete(*keys)
                logger.info(f"ğŸ—‘ï¸ åˆ é™¤ç¼“å­˜: {len(keys)} ä¸ªkey")
        except Exception as e:
            logger.error(f"Redis DELETE_PATTERNå¤±è´¥: {e}")

    def exists(self, key: str) -> bool:
        """æ£€æŸ¥keyæ˜¯å¦å­˜åœ¨"""
        if not self.enabled:
            return False
        try:
            return self.redis_client.exists(key) > 0
        except Exception:
            return False

    # ==================== Hashæ“ä½œ ====================

    def hget(self, key: str, field: str) -> Optional[Any]:
        """è·å–Hashå­—æ®µ"""
        if not self.enabled:
            return None
        try:
            data = self.redis_client.hget(key, field)
            return json.loads(data) if data else None
        except Exception as e:
            logger.error(f"Redis HGETå¤±è´¥: {e}")
            return None

    def hset(self, key: str, field: str, value: Any):
        """è®¾ç½®Hashå­—æ®µ"""
        if not self.enabled:
            return False
        try:
            self.redis_client.hset(
                key,
                field,
                json.dumps(value, ensure_ascii=False, default=str)
            )
            return True
        except Exception as e:
            logger.error(f"Redis HSETå¤±è´¥: {e}")
            return False

    def hgetall(self, key: str) -> dict:
        """è·å–Hashæ‰€æœ‰å­—æ®µ"""
        if not self.enabled:
            return {}
        try:
            data = self.redis_client.hgetall(key)
            return {k: json.loads(v) for k, v in data.items()}
        except Exception as e:
            logger.error(f"Redis HGETALLå¤±è´¥: {e}")
            return {}

    # ==================== Listæ“ä½œ ====================

    def lpush(self, key: str, *values: Any):
        """åˆ—è¡¨å·¦ä¾§æ¨å…¥"""
        if not self.enabled:
            return False
        try:
            serialized = [json.dumps(v, default=str) for v in values]
            self.redis_client.lpush(key, *serialized)
            return True
        except Exception as e:
            logger.error(f"Redis LPUSHå¤±è´¥: {e}")
            return False

    def lrange(self, key: str, start: int = 0, end: int = -1) -> List[Any]:
        """è·å–åˆ—è¡¨èŒƒå›´"""
        if not self.enabled:
            return []
        try:
            data = self.redis_client.lrange(key, start, end)
            return [json.loads(item) for item in data]
        except Exception as e:
            logger.error(f"Redis LRANGEå¤±è´¥: {e}")
            return []

    # ==================== åˆ†å¸ƒå¼é” ====================

    def acquire_lock(self, key: str, expire: int = 10) -> bool:
        """è·å–åˆ†å¸ƒå¼é”"""
        if not self.enabled:
            return True
        try:
            return self.redis_client.set(key, "1", nx=True, ex=expire)
        except Exception:
            return False

    def release_lock(self, key: str):
        """é‡Šæ”¾åˆ†å¸ƒå¼é”"""
        self.delete(key)

    # ==================== è£…é¥°å™¨ ====================

    def cached(self, key_prefix: str, expire: int = None):
        """ç¼“å­˜è£…é¥°å™¨"""
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                # ç”Ÿæˆç¼“å­˜key
                cache_key = self._generate_cache_key(key_prefix, args, kwargs)

                # å°è¯•ä»ç¼“å­˜è·å–
                cached_result = self.get(cache_key)
                if cached_result is not None:
                    logger.debug(f"ğŸ¯ ç¼“å­˜å‘½ä¸­: {cache_key}")
                    return cached_result

                # æ‰§è¡Œå‡½æ•°
                result = func(*args, **kwargs)

                # å†™å…¥ç¼“å­˜
                self.set(cache_key, result, expire)
                logger.debug(f"ğŸ’¾ ç¼“å­˜å†™å…¥: {cache_key}")

                return result
            return wrapper
        return decorator

    def _generate_cache_key(self, prefix: str, args: tuple, kwargs: dict) -> str:
        """ç”Ÿæˆç¼“å­˜key"""
        # å°†å‚æ•°è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶å“ˆå¸Œ
        params_str = json.dumps({
            'args': args,
            'kwargs': kwargs
        }, sort_keys=True, default=str)
        params_hash = hashlib.md5(params_str.encode()).hexdigest()[:8]
        return f"{prefix}:{params_hash}"

# å…¨å±€å®ä¾‹
cache_service = CacheService()
```

---

### é˜¶æ®µ3: åº”ç”¨ç¼“å­˜ (3å¤©)

#### 3.1 ä»»åŠ¡APIç¼“å­˜

```python
# backend/app/api/tasks.py
from app.services.cache_service import cache_service

@router.get("/")
def get_tasks(
    project_id: Optional[str] = None,
    status: Optional[str] = None,
    skip: int = 0,
    limit: int = 100,
    db: Session = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """è·å–ä»»åŠ¡åˆ—è¡¨ï¼ˆå¸¦Redisç¼“å­˜ï¼‰"""

    # 1. ç”Ÿæˆç¼“å­˜key
    cache_key = f"tasks:list:{project_id or 'all'}:{status or 'all'}:{skip}:{limit}"

    # 2. å°è¯•ä»ç¼“å­˜è·å–
    cached_data = cache_service.get(cache_key)
    if cached_data:
        logger.info(f"ğŸ¯ ç¼“å­˜å‘½ä¸­: {cache_key}")
        return cached_data

    # 3. æŸ¥è¯¢æ•°æ®åº“
    query = db.query(Task).options(joinedload(Task.project))

    if project_id:
        query = query.filter(Task.project_id == project_id)
    if status:
        query = query.filter(Task.status == status)

    total = query.count()
    tasks = query.offset(skip).limit(limit).all()

    # 4. æ„å»ºå“åº”
    result = {
        "list": [serialize_task(t) for t in tasks],
        "total": total
    }

    # 5. å†™å…¥ç¼“å­˜ï¼ˆ5åˆ†é’Ÿï¼‰
    cache_service.set(cache_key, result, expire=300)

    return result

# æ¸…é™¤ç¼“å­˜è¾…åŠ©å‡½æ•°
def invalidate_task_cache(task_id: str = None, project_id: str = None):
    """æ¸…é™¤ä»»åŠ¡ç›¸å…³ç¼“å­˜"""
    if task_id:
        cache_service.delete(f"tasks:detail:{task_id}")
    if project_id:
        cache_service.delete_pattern(f"tasks:list:{project_id}:*")
    cache_service.delete_pattern("tasks:list:all:*")

@router.post("/")
def create_task(task_data: TaskCreate, db: Session = Depends(get_db)):
    # ... åˆ›å»ºä»»åŠ¡ ...
    db.commit()

    # âœ… æ¸…é™¤ç¼“å­˜
    invalidate_task_cache(project_id=task_data.project_id)

    return db_task
```

---

#### 3.2 ç”¨æˆ·ä¿¡æ¯ç¼“å­˜

```python
# backend/app/services/user_cache_service.py
from app.services.cache_service import cache_service
from app.models.user import User

class UserCacheService:
    @staticmethod
    def get_user_info(user_id: str, db: Session) -> dict:
        """è·å–ç”¨æˆ·ä¿¡æ¯ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        cache_key = f"user:info:{user_id}"

        # ä»ç¼“å­˜è·å–
        cached = cache_service.get(cache_key)
        if cached:
            return cached

        # æŸ¥è¯¢æ•°æ®åº“
        user = db.query(User).filter(User.id == user_id).first()
        if not user:
            return None

        user_info = {
            "id": user.id,
            "username": user.username,
            "real_name": user.real_name,
            "role": user.role,
            "department": user.department
        }

        # å†™å…¥ç¼“å­˜ï¼ˆ30åˆ†é’Ÿï¼‰
        cache_service.set(cache_key, user_info, expire=1800)

        return user_info

    @staticmethod
    def get_active_users(db: Session) -> List[dict]:
        """è·å–æ´»è·ƒç”¨æˆ·åˆ—è¡¨ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        cache_key = "user:list:active"

        cached = cache_service.get(cache_key)
        if cached:
            return cached

        users = db.query(User).filter(User.status == "active").all()
        user_list = [
            {
                "id": u.id,
                "username": u.username,
                "real_name": u.real_name,
                "role": u.role
            }
            for u in users
        ]

        cache_service.set(cache_key, user_list, expire=1800)
        return user_list

    @staticmethod
    def invalidate_user_cache(user_id: str):
        """æ¸…é™¤ç”¨æˆ·ç¼“å­˜"""
        cache_service.delete(f"user:info:{user_id}")
        cache_service.delete("user:list:active")

user_cache_service = UserCacheService()
```

---

#### 3.3 ç»Ÿè®¡æ•°æ®ç¼“å­˜

```python
# backend/app/api/dashboard.py
from app.services.cache_service import cache_service

@router.get("/stats")
def get_dashboard_stats(
    db: Session = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """è·å–ä»ªè¡¨æ¿ç»Ÿè®¡ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    cache_key = f"stats:dashboard:user:{current_user.id}"

    # å°è¯•ä»ç¼“å­˜è·å–
    cached = cache_service.get(cache_key)
    if cached:
        return cached

    # å¤æ‚ç»Ÿè®¡æŸ¥è¯¢
    stats = {
        "my_tasks_count": db.query(Task).filter(
            Task.assigned_to == current_user.id,
            Task.status.in_(["in_progress", "submitted"])
        ).count(),

        "completed_today": db.query(Task).filter(
            Task.assigned_to == current_user.id,
            Task.status == "approved",
            func.date(Task.reviewed_at) == date.today()
        ).count(),

        # ... æ›´å¤šç»Ÿè®¡ ...
    }

    # ç¼“å­˜15åˆ†é’Ÿ
    cache_service.set(cache_key, stats, expire=900)

    return stats
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| åœºæ™¯         | ä¼˜åŒ–å‰  | Redisç¼“å­˜å | æå‡       |
| ------------ | ------- | ----------- | ---------- |
| ä»»åŠ¡åˆ—è¡¨åŠ è½½ | ~800ms  | ~50ms       | **94%** âš¡ |
| é¡¹ç›®åˆ—è¡¨æŸ¥è¯¢ | ~500ms  | ~10ms       | **98%** âš¡ |
| ç”¨æˆ·ä¿¡æ¯æŸ¥è¯¢ | ~200ms  | ~5ms        | **97%** âš¡ |
| ä»ªè¡¨æ¿ç»Ÿè®¡   | ~3000ms | ~500ms      | **83%** âš¡ |
| æ–‡ç« è¯¦æƒ…åŠ è½½ | ~800ms  | ~50ms       | **94%** âš¡ |
| å¹¶å‘1000è¯·æ±‚ | è¶…æ—¶50% | æˆåŠŸ100%    | âœ…         |

**ç»¼åˆæå‡**: å¹³å‡å“åº”æ—¶é—´é™ä½ **85-90%**

---

## ğŸš€ éƒ¨ç½²æŒ‡å—

### å¼€å‘ç¯å¢ƒ

```bash
# 1. å®‰è£…Redis
brew install redis  # macOS
sudo apt install redis-server  # Ubuntu

# 2. å¯åŠ¨Redis
redis-server

# 3. æµ‹è¯•
redis-cli ping
```

### ç”Ÿäº§ç¯å¢ƒ

```bash
# 1. å®‰è£…Redis
sudo apt update
sudo apt install redis-server

# 2. é…ç½®Redis
sudo nano /etc/redis/redis.conf

# ä¿®æ”¹ä»¥ä¸‹é…ç½®:
bind 127.0.0.1  # åªç›‘å¬æœ¬åœ°
maxmemory 2gb   # æœ€å¤§å†…å­˜
maxmemory-policy allkeys-lru  # å†…å­˜æ·˜æ±°ç­–ç•¥

# 3. å¯åŠ¨å¹¶è®¾ç½®å¼€æœºè‡ªå¯
sudo systemctl start redis
sudo systemctl enable redis

# 4. æ£€æŸ¥çŠ¶æ€
sudo systemctl status redis
```

### RedisæŒä¹…åŒ–é…ç½®

```bash
# åœ¨ redis.conf ä¸­é…ç½®
save 900 1      # 900ç§’å†…æœ‰1ä¸ªkeyå˜åŒ–åˆ™ä¿å­˜
save 300 10     # 300ç§’å†…æœ‰10ä¸ªkeyå˜åŒ–åˆ™ä¿å­˜
save 60 10000   # 60ç§’å†…æœ‰10000ä¸ªkeyå˜åŒ–åˆ™ä¿å­˜

appendonly yes  # å¯ç”¨AOFæŒä¹…åŒ–
appendfsync everysec  # æ¯ç§’åŒæ­¥
```

---

## ğŸ“ˆ ç›‘æ§ä¸ç»´æŠ¤

### Redisç›‘æ§è„šæœ¬

```python
# backend/scripts/redis_monitor.py
import redis
from datetime import datetime

def monitor_redis():
    client = redis.Redis(host='localhost', port=6379, db=0)
    info = client.info()

    print("=" * 60)
    print(f"Redis ç›‘æ§æŠ¥å‘Š - {datetime.now()}")
    print("=" * 60)
    print(f"âœ… å·²ç”¨å†…å­˜: {info['used_memory_human']}")
    print(f"ğŸ“Š Keyæ€»æ•°: {client.dbsize()}")
    print(f"ğŸ¯ å‘½ä¸­ç‡: {info.get('keyspace_hits', 0) / (info.get('keyspace_hits', 1) + info.get('keyspace_misses', 1)) * 100:.2f}%")
    print(f"âš¡ æ¯ç§’æ“ä½œ: {info['instantaneous_ops_per_sec']}")
    print(f"ğŸ‘¥ è¿æ¥æ•°: {info['connected_clients']}")
    print("=" * 60)

if __name__ == '__main__':
    monitor_redis()
```

### æ¸…ç†ç¼“å­˜è„šæœ¬

```python
# backend/scripts/clear_cache.py
from app.services.cache_service import cache_service

def clear_all_cache():
    """æ¸…é™¤æ‰€æœ‰ç¼“å­˜"""
    patterns = [
        "tasks:*",
        "projects:*",
        "user:*",
        "stats:*",
        "article:*"
    ]

    for pattern in patterns:
        cache_service.delete_pattern(pattern)
        print(f"âœ… å·²æ¸…é™¤: {pattern}")

if __name__ == '__main__':
    clear_all_cache()
```

---

## ğŸ“ æœ€ä½³å®è·µ

### 1. ç¼“å­˜å‘½åè§„èŒƒ

```
{æ¨¡å—}:{ç±»å‹}:{æ ‡è¯†}:{å‚æ•°}
ä¾‹å¦‚: tasks:list:project1:page1
```

### 2. è¿‡æœŸæ—¶é—´è®¾ç½®

- **çƒ­ç‚¹æ•°æ®**: 5-10åˆ†é’Ÿ
- **ç”¨æˆ·ä¿¡æ¯**: 30åˆ†é’Ÿ
- **ç»Ÿè®¡æ•°æ®**: 15åˆ†é’Ÿ
- **é…ç½®æ•°æ®**: 1å°æ—¶

### 3. ç¼“å­˜æ›´æ–°ç­–ç•¥

- **Cache-Aside**: å…ˆæŸ¥ç¼“å­˜ï¼Œmissåˆ™æŸ¥DBå¹¶å†™å…¥ç¼“å­˜ï¼ˆæ¨èï¼‰
- **Write-Through**: å†™æ“ä½œåŒæ—¶æ›´æ–°ç¼“å­˜
- **Write-Behind**: å¼‚æ­¥æ›´æ–°ç¼“å­˜

### 4. ç¼“å­˜ç©¿é€é˜²æŠ¤

```python
# ç©ºå€¼ä¹Ÿç¼“å­˜ï¼Œé˜²æ­¢æ¶æ„æŸ¥è¯¢ä¸å­˜åœ¨çš„æ•°æ®
if result is None:
    cache_service.set(cache_key, "NULL", expire=60)
```

---

## ğŸ¯ å®æ–½ä¼˜å…ˆçº§

### ç¬¬1å‘¨ (å¿…é¡»å®Œæˆ)

- [x] âœ… æ•°æ®åº“ç´¢å¼•ä¼˜åŒ– - å·²å®Œæˆ
- [ ] ğŸš€ RedisåŸºç¡€è®¾æ–½éƒ¨ç½²
- [ ] ğŸš€ ä»»åŠ¡åˆ—è¡¨ç¼“å­˜
- [ ] ğŸš€ é¡¹ç›®åˆ—è¡¨ç¼“å­˜
- [ ] ğŸš€ ç”¨æˆ·ä¿¡æ¯ç¼“å­˜

**é¢„æœŸæ•ˆæœ**: é¡µé¢åŠ è½½é€Ÿåº¦æå‡ **80%**

### ç¬¬2å‘¨ (å¼ºçƒˆæ¨è)

- [ ] ğŸ“Š ç»Ÿè®¡æ•°æ®ç¼“å­˜
- [ ] ğŸ“ æ–‡ç« /çŸ¥è¯†åº“ç¼“å­˜
- [ ] ğŸ”” å®æ—¶é€šçŸ¥ä¼˜åŒ–

**é¢„æœŸæ•ˆæœ**: ç»Ÿè®¡æŸ¥è¯¢æå‡ **85%**ï¼Œé€šçŸ¥å®æ—¶æ€§æå‡ **90%**

### ç¬¬3å‘¨ (ä¼˜åŒ–ä½“éªŒ)

- [ ] ğŸ” ä¼šè¯ç®¡ç†ä¼˜åŒ–
- [ ] ğŸ” æœç´¢ç»“æœç¼“å­˜
- [ ] ğŸ›¡ï¸ é™æµæ§åˆ¶

**é¢„æœŸæ•ˆæœ**: ç³»ç»Ÿç¨³å®šæ€§æå‡ **50%**

---

## ğŸ“ éœ€è¦å¸®åŠ©?

å¦‚æœéœ€è¦å®æ–½Redisä¼˜åŒ–ï¼Œæˆ‘å¯ä»¥å¸®ä½ ï¼š

1. âœ… åˆ›å»ºå®Œæ•´çš„ç¼“å­˜æœåŠ¡ä»£ç 
2. âœ… ä¿®æ”¹APIæ¥å£é›†æˆç¼“å­˜
3. âœ… é…ç½®Redisç”Ÿäº§ç¯å¢ƒ
4. âœ… ç¼–å†™ç›‘æ§å’Œç»´æŠ¤è„šæœ¬
5. âœ… æµ‹è¯•æ€§èƒ½æå‡æ•ˆæœ

---

**æ€»ç»“**: Redisç¼“å­˜å¯ä»¥è®©ä½ çš„ç³»ç»Ÿæ€§èƒ½å†æå‡ **80-90%**ï¼Œå°†å¹³å‡å“åº”æ—¶é—´ä»ç§’çº§é™åˆ°æ¯«ç§’çº§ï¼ğŸš€
