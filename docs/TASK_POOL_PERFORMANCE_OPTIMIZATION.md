# ä»»åŠ¡æ± æ€§èƒ½ä¼˜åŒ–æ–¹æ¡ˆ

## ğŸ” æ€§èƒ½ç“¶é¢ˆåˆ†æ

### å½“å‰é—®é¢˜

- **ä»»åŠ¡æ•°é‡**: 450+ ä¸ªä»»åŠ¡
- **åŠ è½½ç¼“æ…¢**: ç‚¹å‡»ä»»åŠ¡æ± é¡µé¢ååŠ è½½æ˜æ˜¾å»¶è¿Ÿ
- **ç”¨æˆ·ä½“éªŒ**: å½±å“ä½¿ç”¨æµç•…åº¦

### ç“¶é¢ˆå®šä½

#### 1. **æ•°æ®åº“æŸ¥è¯¢æ…¢** (ä¸»è¦ç“¶é¢ˆ - å 70%)

```python
# backend/app/api/tasks.py:229-232
total_tasks = query.count()  # âŒ å…¨è¡¨æ‰«æï¼Œæ²¡æœ‰ç´¢å¼•
tasks = query.offset(skip).limit(limit).all()  # âŒ æ²¡æœ‰eager loading
```

**é—®é¢˜**:

- `status`ã€`assigned_to` å­—æ®µæ²¡æœ‰ç´¢å¼•
- `query.count()` éœ€è¦æ‰«ææ‰€æœ‰è¡Œ
- JOINæŸ¥è¯¢ä½†æ²¡æœ‰ä½¿ç”¨`joinedload`ä¼˜åŒ–
- æ¯æ¬¡è¯·æ±‚éƒ½æŸ¥è¯¢æ•°æ®åº“

#### 2. **åç«¯æ•°æ®å¤„ç†æ…¢** (å 20%)

```python
# backend/app/api/tasks.py:236-264
for task in tasks:
    task_dict = {
        "project_name": task.project.name,  # âŒ å¯èƒ½è§¦å‘N+1æŸ¥è¯¢
        ...  # å¤§é‡å­—æ®µæ˜ å°„
    }
```

**é—®é¢˜**:

- å¾ªç¯æ„å»ºå­—å…¸å¼€é”€å¤§
- å…³è”æŸ¥è¯¢å¯èƒ½è§¦å‘é¢å¤–SQL

#### 3. **å‰ç«¯æ¸²æŸ“æ…¢** (å 10%)

```typescript
// src/views/project/task-pool/index.vue:147, 746
getUserName(row.assignedTo, row) // âŒ æ¯è¡Œéƒ½è°ƒç”¨
getTaskProjectCategory(task) // âŒ æ¯è¡Œéƒ½æŸ¥æ‰¾é¡¹ç›®
```

**é—®é¢˜**:

- è¡¨æ ¼æ¯è¡Œæ¸²æŸ“æ—¶éƒ½è°ƒç”¨å‡½æ•°
- æŸ¥æ‰¾é¡¹ç›®åˆ—è¡¨çš„å¼€é”€

---

## âœ… ä¼˜åŒ–æ–¹æ¡ˆ

### æ–¹æ¡ˆ1: æ·»åŠ æ•°æ®åº“ç´¢å¼• (æœ€é‡è¦ï¼)

#### 1.1 åˆ›å»ºæ•°æ®åº“è¿ç§»è„šæœ¬

```python
# backend/alembic/versions/xxxx_add_task_indexes.py
"""add indexes for task performance

Revision ID: xxxx
Create Date: 2025-10-31
"""
from alembic import op
import sqlalchemy as sa

def upgrade():
    # ä¸ºå¸¸ç”¨æŸ¥è¯¢å­—æ®µæ·»åŠ ç´¢å¼•
    op.create_index('idx_tasks_status', 'tasks', ['status'])
    op.create_index('idx_tasks_assigned_to', 'tasks', ['assigned_to'])
    op.create_index('idx_tasks_created_at', 'tasks', ['created_at'])
    op.create_index('idx_tasks_project_status', 'tasks', ['project_id', 'status'])

    # ä¸ºProjectè¡¨æ·»åŠ statusç´¢å¼•ï¼ˆç”¨äºè¿‡æ»¤completedé¡¹ç›®ï¼‰
    op.create_index('idx_projects_status', 'projects', ['status'])

def downgrade():
    op.drop_index('idx_tasks_status', 'tasks')
    op.drop_index('idx_tasks_assigned_to', 'tasks')
    op.drop_index('idx_tasks_created_at', 'tasks')
    op.drop_index('idx_tasks_project_status', 'tasks')
    op.drop_index('idx_projects_status', 'projects')
```

**æ‰§è¡Œè¿ç§»**:

```bash
cd backend
alembic revision --autogenerate -m "add indexes for task performance"
alembic upgrade head
```

#### 1.2 æ›´æ–°Taskæ¨¡å‹

```python
# backend/app/models/task.py
from sqlalchemy import Column, String, DateTime, Text, Integer, ForeignKey, JSON, Index
from sqlalchemy.orm import relationship
from sqlalchemy.sql import func
from app.database import Base
import uuid

class Task(Base):
    __tablename__ = "tasks"

    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    title = Column(String(200), nullable=False, index=True)
    description = Column(Text)
    project_id = Column(String(36), ForeignKey("projects.id", ondelete="CASCADE"), nullable=False, index=True)
    status = Column(String(20), default="pending", index=True)  # âœ… æ·»åŠ ç´¢å¼•
    priority = Column(String(20), default="medium")
    assigned_to = Column(String(36), ForeignKey("users.id"), index=True)  # âœ… æ·»åŠ ç´¢å¼•
    # ... å…¶ä»–å­—æ®µä¿æŒä¸å˜
    created_at = Column(DateTime, server_default=func.now(), index=True)  # âœ… æ·»åŠ ç´¢å¼•
    updated_at = Column(DateTime, server_default=func.now(), onupdate=func.now())

    # ... relationshipå®šä¹‰ä¿æŒä¸å˜

    # âœ… æ·»åŠ å¤åˆç´¢å¼•
    __table_args__ = (
        Index('idx_task_project_status', 'project_id', 'status'),
        Index('idx_task_status_assigned', 'status', 'assigned_to'),
    )
```

**é¢„æœŸæ•ˆæœ**: æŸ¥è¯¢é€Ÿåº¦æå‡ **60-80%**

---

### æ–¹æ¡ˆ2: ä½¿ç”¨Redisç¼“å­˜ (æ¨èï¼)

#### 2.1 å®‰è£…Redisä¾èµ–

```bash
pip install redis
```

#### 2.2 åˆ›å»ºRedisç¼“å­˜æœåŠ¡

```python
# backend/app/services/cache_service.py
import redis
import json
from typing import Optional, Any
from datetime import timedelta
import logging

logger = logging.getLogger(__name__)

class CacheService:
    def __init__(self):
        # æ ¹æ®ç¯å¢ƒé…ç½®è¿æ¥Redis
        self.redis_client = redis.Redis(
            host='localhost',
            port=6379,
            db=0,
            decode_responses=True,
            socket_connect_timeout=2,
            socket_timeout=2
        )
        self.enabled = self._check_redis_available()

    def _check_redis_available(self) -> bool:
        """æ£€æŸ¥Redisæ˜¯å¦å¯ç”¨"""
        try:
            self.redis_client.ping()
            logger.info("âœ… Redisè¿æ¥æˆåŠŸ")
            return True
        except Exception as e:
            logger.warning(f"âš ï¸ Redisä¸å¯ç”¨ï¼Œå°†è·³è¿‡ç¼“å­˜: {e}")
            return False

    def get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜"""
        if not self.enabled:
            return None
        try:
            data = self.redis_client.get(key)
            if data:
                return json.loads(data)
            return None
        except Exception as e:
            logger.error(f"âŒ Redis GETå¤±è´¥: {e}")
            return None

    def set(self, key: str, value: Any, expire: int = 300):
        """è®¾ç½®ç¼“å­˜ï¼Œé»˜è®¤5åˆ†é’Ÿè¿‡æœŸ"""
        if not self.enabled:
            return False
        try:
            self.redis_client.setex(
                key,
                expire,
                json.dumps(value, ensure_ascii=False, default=str)
            )
            return True
        except Exception as e:
            logger.error(f"âŒ Redis SETå¤±è´¥: {e}")
            return False

    def delete(self, key: str):
        """åˆ é™¤ç¼“å­˜"""
        if not self.enabled:
            return
        try:
            self.redis_client.delete(key)
        except Exception as e:
            logger.error(f"âŒ Redis DELETEå¤±è´¥: {e}")

    def delete_pattern(self, pattern: str):
        """æ‰¹é‡åˆ é™¤åŒ¹é…çš„key"""
        if not self.enabled:
            return
        try:
            keys = self.redis_client.keys(pattern)
            if keys:
                self.redis_client.delete(*keys)
                logger.info(f"ğŸ—‘ï¸ åˆ é™¤ç¼“å­˜: {len(keys)} ä¸ªkeyåŒ¹é… {pattern}")
        except Exception as e:
            logger.error(f"âŒ Redis DELETE_PATTERNå¤±è´¥: {e}")

# å…¨å±€å®ä¾‹
cache_service = CacheService()
```

#### 2.3 ä¼˜åŒ–ä»»åŠ¡APIä½¿ç”¨ç¼“å­˜

```python
# backend/app/api/tasks.py
from app.services.cache_service import cache_service

@router.get("/", include_in_schema=True)
def get_tasks(
    project_id: Optional[str] = None,
    status: Optional[str] = None,
    assigned_to: Optional[str] = None,
    skip: int = 0,
    limit: int = 100,
    include_completed_projects: bool = False,
    db: Session = Depends(get_db),
    current_user = Depends(require_permission(["TaskPool", "ProjectManagement"]))
):
    """è·å–ä»»åŠ¡åˆ—è¡¨ï¼ˆå¸¦Redisç¼“å­˜ï¼‰"""

    # âœ… 1. ç”Ÿæˆç¼“å­˜key
    cache_key = f"tasks:list:{project_id or 'all'}:{status or 'all'}:{assigned_to or 'all'}:{skip}:{limit}:{include_completed_projects}"

    # âœ… 2. å°è¯•ä»ç¼“å­˜è·å–
    cached_data = cache_service.get(cache_key)
    if cached_data:
        logger.info(f"ğŸ¯ [TaskAPI] å‘½ä¸­ç¼“å­˜: {cache_key}")
        return cached_data

    logger.info(f"ğŸ“‹ [TaskAPI] ç¼“å­˜æœªå‘½ä¸­ï¼ŒæŸ¥è¯¢æ•°æ®åº“: {cache_key}")

    # âœ… 3. ä½¿ç”¨joinedloadä¼˜åŒ–JOINæŸ¥è¯¢
    from sqlalchemy.orm import joinedload
    query = db.query(Task).options(joinedload(Task.project)).join(
        Project, Task.project_id == Project.id
    )

    if not include_completed_projects:
        query = query.filter(Project.status != "completed")

    if project_id:
        query = query.filter(Task.project_id == project_id)
    if status:
        if status == "accepted":
            query = query.filter(Task.status.in_(["submitted", "skip_pending", "skipped", "approved", "rejected"]))
        else:
            query = query.filter(Task.status == status)
    if assigned_to:
        query = query.filter(Task.assigned_to == assigned_to)

    # âœ… 4. ä¼˜åŒ–countæŸ¥è¯¢ - ä½¿ç”¨å­æŸ¥è¯¢æˆ–è€…ç¼“å­˜total
    total_tasks = query.count()

    # âœ… 5. æ‰¹é‡æŸ¥è¯¢tasks
    tasks = query.order_by(Task.created_at.desc()).offset(skip).limit(limit).all()

    # âœ… 6. æ„å»ºå“åº”
    task_responses = []
    for task in tasks:
        task_dict = {
            "id": task.id,
            "title": task.title,
            "description": task.description,
            "project_id": task.project_id,
            "project_name": task.project.name if task.project else "æœªçŸ¥é¡¹ç›®",
            "status": task.status,
            "priority": task.priority,
            "assigned_to": task.assigned_to,
            "assigned_to_name": task.assigned_to_name,
            "created_by": task.created_by,
            "created_by_name": task.created_by_name,
            "image_url": task.image_url,
            "annotation_data": task.annotation_data,
            "score": task.score,
            "assigned_at": task.assigned_at.isoformat() if task.assigned_at else None,
            "submitted_at": task.submitted_at.isoformat() if task.submitted_at else None,
            "reviewed_by": task.reviewed_by,
            "reviewed_by_name": task.reviewed_by_name,
            "reviewed_at": task.reviewed_at.isoformat() if task.reviewed_at else None,
            "review_comment": task.review_comment,
            "created_at": task.created_at.isoformat() if task.created_at else None,
            "updated_at": task.updated_at.isoformat() if task.updated_at else None,
            "attachments": task.attachments or [],
            "timeline": task.timeline or []
        }
        task_responses.append(task_dict)

    result = {"list": task_responses, "total": total_tasks}

    # âœ… 7. å†™å…¥ç¼“å­˜ï¼ˆ5åˆ†é’Ÿè¿‡æœŸï¼‰
    cache_service.set(cache_key, result, expire=300)
    logger.info(f"ğŸ’¾ [TaskAPI] å·²ç¼“å­˜ç»“æœ: {cache_key}")

    return result

# âœ… 8. åœ¨ä»»åŠ¡æ›´æ–°æ—¶æ¸…é™¤ç›¸å…³ç¼“å­˜
def invalidate_task_cache(project_id: str = None):
    """æ¸…é™¤ä»»åŠ¡åˆ—è¡¨ç¼“å­˜"""
    if project_id:
        cache_service.delete_pattern(f"tasks:list:{project_id}:*")
    cache_service.delete_pattern("tasks:list:all:*")
    logger.info(f"ğŸ—‘ï¸ [TaskAPI] å·²æ¸…é™¤ä»»åŠ¡ç¼“å­˜")

# åœ¨åˆ›å»ºã€æ›´æ–°ã€åˆ é™¤ä»»åŠ¡æ—¶è°ƒç”¨
@router.post("/", response_model=TaskResponse)
def create_task(task_data: TaskCreate, db: Session = Depends(get_db), current_user = Depends(require_permission("TaskPool"))):
    # ... åˆ›å»ºä»»åŠ¡é€»è¾‘ ...
    db.commit()

    # âœ… æ¸…é™¤ç¼“å­˜
    invalidate_task_cache(task_data.project_id)

    return db_task
```

**é¢„æœŸæ•ˆæœ**:

- é¦–æ¬¡åŠ è½½: ä¸å½“å‰ç›¸åŒ
- åç»­åŠ è½½: **æå‡ 90-95%** (ä»Redisè¯»å–ä»…éœ€ 10-20ms)
- ç¼“å­˜å‘½ä¸­ç‡: **70-80%**

---

### æ–¹æ¡ˆ3: å‰ç«¯ä¼˜åŒ–

#### 3.1 ç¼“å­˜ç”¨æˆ·å’Œé¡¹ç›®æ˜ å°„

```typescript
// src/views/project/task-pool/index.vue

// âœ… 1. é¢„å…ˆæ„å»ºæ˜ å°„è¡¨
const userNameMap = ref<Record<string, string>>({})
const projectCategoryMap = ref<Record<string, { category: string; subCategory: string }>>({})

// âœ… 2. åœ¨æ•°æ®åŠ è½½åæ„å»ºæ˜ å°„
const fetchTasks = async () => {
  const params = {
    /* ... */
  }
  await projectStore.fetchTasks(params)

  // æ„å»ºç”¨æˆ·åæ˜ å°„
  projectStore.tasks.forEach((task) => {
    if (task.assignedTo && task.assignedToName) {
      userNameMap.value[task.assignedTo] = task.assignedToName
    }
  })

  // æ„å»ºé¡¹ç›®åˆ†ç±»æ˜ å°„
  projectStore.projects.forEach((project) => {
    projectCategoryMap.value[project.id] = {
      category: project.category || '',
      subCategory: project.subCategory || ''
    }
  })
}

// âœ… 3. ä½¿ç”¨æ˜ å°„è¡¨ï¼ˆO(1)æŸ¥æ‰¾ï¼‰
const getUserName = (userId: string | undefined | null, row?: any) => {
  if (!userId) return 'æœªåˆ†é…'
  // ä¼˜å…ˆä½¿ç”¨è¡Œæ•°æ®ä¸­çš„å†—ä½™å­—æ®µ
  if (row?.assignedToName || row?.assigned_to_name) {
    return row.assignedToName || row.assigned_to_name
  }
  // ä»æ˜ å°„è¡¨æŸ¥æ‰¾ï¼ˆå¿«é€Ÿï¼‰
  return userNameMap.value[userId] || `ç”¨æˆ·${String(userId).slice(-4)}`
}

const getTaskProjectCategory = (task: any) => {
  const projectId = task.projectId || task.project_id
  return projectCategoryMap.value[projectId] || { category: '', subCategory: '' }
}
```

#### 3.2 æ·»åŠ åŠ è½½çŠ¶æ€æç¤º

```vue
<!-- src/views/project/task-pool/index.vue -->
<el-table
  v-loading="projectStore.loading"
  :data="projectStore.tasks"
  stripe
  height="calc(100vh - 420px)"
  element-loading-text="åŠ è½½ä»»åŠ¡æ•°æ®ä¸­..."
  element-loading-spinner="el-icon-loading"
  element-loading-background="rgba(0, 0, 0, 0.5)"
></el-table>
```

**é¢„æœŸæ•ˆæœ**: è¡¨æ ¼æ¸²æŸ“é€Ÿåº¦æå‡ **30-40%**

---

### æ–¹æ¡ˆ4: è™šæ‹Ÿæ»šåŠ¨ (å¯é€‰ï¼Œé’ˆå¯¹è¶…å¤§æ•°æ®é‡)

å¦‚æœä»»åŠ¡æ•°é‡è¶…è¿‡1000ä¸ªï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨è™šæ‹Ÿæ»šåŠ¨ï¼š

```bash
npm install vue-virtual-scroller
```

```vue
<template>
  <RecycleScroller :items="projectStore.tasks" :item-size="60" key-field="id" v-slot="{ item }">
    <TaskRow :task="item" />
  </RecycleScroller>
</template>
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| ä¼˜åŒ–æ–¹æ¡ˆ   | é¢„æœŸæå‡ | å®æ–½éš¾åº¦    | æ¨èåº¦            |
| ---------- | -------- | ----------- | ----------------- |
| æ•°æ®åº“ç´¢å¼• | 60-80%   | â­ ç®€å•     | â­â­â­â­â­        |
| Redisç¼“å­˜  | 90-95%   | â­â­ ä¸­ç­‰   | â­â­â­â­â­        |
| å‰ç«¯æ˜ å°„è¡¨ | 30-40%   | â­ ç®€å•     | â­â­â­â­          |
| è™šæ‹Ÿæ»šåŠ¨   | 50-70%   | â­â­â­ å¤æ‚ | â­â­ (ä»…å¤§æ•°æ®é‡) |

## ğŸ¯ å®æ–½å»ºè®®

### ä¼˜å…ˆçº§1 (å¿…é¡»): æ•°æ®åº“ç´¢å¼•

1. åˆ›å»ºè¿ç§»è„šæœ¬
2. æ‰§è¡Œ `alembic upgrade head`
3. éªŒè¯ç´¢å¼•åˆ›å»ºæˆåŠŸ: `SHOW INDEX FROM tasks;`

### ä¼˜å…ˆçº§2 (å¼ºçƒˆæ¨è): Redisç¼“å­˜

1. å®‰è£…Redis: `sudo apt install redis-server` æˆ– `brew install redis`
2. å¯åŠ¨Redis: `redis-server`
3. æ·»åŠ ç¼“å­˜æœåŠ¡ä»£ç 
4. æµ‹è¯•ç¼“å­˜åŠŸèƒ½

### ä¼˜å…ˆçº§3 (æ¨è): å‰ç«¯ä¼˜åŒ–

1. å®ç°æ˜ å°„è¡¨ä¼˜åŒ–
2. æ·»åŠ åŠ è½½æç¤º

---

## âš¡ é¢„æœŸæ€»ä½“æ•ˆæœ

**ç»„åˆä¼˜åŒ–å**:

- é¦–æ¬¡åŠ è½½: **æå‡ 70-80%** (ç´¢å¼• + å‰ç«¯ä¼˜åŒ–)
- åç»­åŠ è½½: **æå‡ 95%+** (Redisç¼“å­˜å‘½ä¸­)
- ä» **~3ç§’** é™åˆ° **~0.3ç§’**

---

## ğŸ”§ å¿«é€ŸéªŒè¯

### 1. æ£€æŸ¥å½“å‰æ€§èƒ½

```sql
-- åœ¨MySQLä¸­æ‰§è¡Œ
EXPLAIN SELECT * FROM tasks
JOIN projects ON tasks.project_id = projects.id
WHERE projects.status != 'completed'
ORDER BY tasks.created_at DESC
LIMIT 20;
```

### 2. æ·»åŠ ç´¢å¼•åå¯¹æ¯”

```sql
-- å†æ¬¡æ‰§è¡ŒEXPLAINï¼Œå¯¹æ¯”typeã€rowsã€Extraå­—æ®µ
-- ä¼˜åŒ–ååº”è¯¥çœ‹åˆ° type=index æˆ– type=refï¼Œrowså‡å°‘
```

### 3. Redisç¼“å­˜éªŒè¯

```bash
# ç»ˆç«¯1: ç›‘æ§Redis
redis-cli MONITOR

# ç»ˆç«¯2: è®¿é—®ä»»åŠ¡æ± é¡µé¢
# æŸ¥çœ‹ç»ˆç«¯1æ˜¯å¦æœ‰GET/SETæ“ä½œ
```

---

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **RedisæŒä¹…åŒ–**: ç”Ÿäº§ç¯å¢ƒå»ºè®®é…ç½®AOFæˆ–RDBæŒä¹…åŒ–
2. **ç¼“å­˜ä¸€è‡´æ€§**: ä»»åŠ¡æ›´æ–°æ—¶åŠ¡å¿…æ¸…é™¤ç›¸å…³ç¼“å­˜
3. **ç´¢å¼•ç»´æŠ¤**: å®šæœŸåˆ†ææ…¢æŸ¥è¯¢æ—¥å¿—ï¼Œè°ƒæ•´ç´¢å¼•ç­–ç•¥
4. **ç›‘æ§**: ä½¿ç”¨Redis INFOå‘½ä»¤ç›‘æ§ç¼“å­˜å‘½ä¸­ç‡

---

éœ€è¦æˆ‘å¸®ä½ å®æ–½è¿™äº›ä¼˜åŒ–å—ï¼Ÿå»ºè®®ä»**æ•°æ®åº“ç´¢å¼•**å¼€å§‹ï¼Œè¿™æ˜¯æŠ•å…¥äº§å‡ºæ¯”æœ€é«˜çš„ä¼˜åŒ–ï¼
